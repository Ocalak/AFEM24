{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7WOGJNW07W9vIboQf15wM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ocalak/AFEM24/blob/main/Firstpreds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wZzGFxNK1-r7",
        "outputId": "311ac68d-bb08-4f62-f649-f3bda7cecdd4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.32)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
            "Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 optuna-3.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uXy8pRq02Eq",
        "outputId": "50ba11d1-f658-4f2f-b84c-6939a2ea54d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-27 21:58:25,716] A new study created in memory with name: no-name-b3647d7b-a8ef-4a2a-89b7-77ac7b6e2119\n",
            "[I 2024-08-27 21:59:09,658] Trial 0 finished with value: 0.27420687675476074 and parameters: {'use_temp_actual': True, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': False, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': True, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': True, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': False, 'use_Rolling_Std_30': True, 'use_temp_lag_1': False, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': False, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': True, 'use_temp_min': True, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': True, 'regularize_h1_kernel': True, 'h1_activation_rate_l1': 0.0003116120132093292, 'h1_kernel_rate_l1': 0.32457658162626185, 'neurons_1': 243, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': False, 'neurons_2': 101, 'activation_2': 'tanh', 'learning_rate': 0.00017206652354503945}. Best is trial 0 with value: 0.27420687675476074.\n",
            "[I 2024-08-27 22:01:57,408] Trial 1 finished with value: 0.10548137128353119 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 251, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.0005226307692004072, 'neurons_2': 251, 'activation_2': 'softmax', 'learning_rate': 0.002140671391829444}. Best is trial 1 with value: 0.10548137128353119.\n",
            "[I 2024-08-27 22:02:25,697] Trial 2 finished with value: 0.4290354251861572 and parameters: {'use_temp_actual': True, 'use_hour': False, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': True, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': False, 'use_temp_lag_2': True, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': False, 'use_temp_lag_24': False, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': False, 'dropout': True, 'dropout_rate': 0.905449488813964, 'regularize_h1_activation': False, 'regularize_h1_kernel': True, 'h1_kernel_rate_l1': 0.056498313711028925, 'neurons_1': 251, 'activation_1': 'softplus', 'regularize_h2_activation': True, 'regularize_h2_kernel': False, 'h2_activation_rate_l1': 2.2947708280559445, 'neurons_2': 110, 'activation_2': 'elu', 'learning_rate': 0.004950231224447163}. Best is trial 1 with value: 0.10548137128353119.\n",
            "[I 2024-08-27 22:05:19,198] Trial 3 finished with value: 0.15896061062812805 and parameters: {'use_temp_actual': False, 'use_hour': False, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': True, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': False, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': False, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': False, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 177, 'activation_1': 'elu', 'regularize_h2_activation': True, 'regularize_h2_kernel': False, 'h2_activation_rate_l1': 0.012283266791402668, 'neurons_2': 46, 'activation_2': 'softplus', 'learning_rate': 1.551973347088295e-05}. Best is trial 1 with value: 0.10548137128353119.\n",
            "[I 2024-08-27 22:06:32,173] Trial 4 finished with value: 0.2965029776096344 and parameters: {'use_temp_actual': True, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': False, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': True, 'use_Rolling_Std_15': False, 'use_Rolling_Sum_15': True, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': False, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': False, 'use_temp_mean_24': False, 'use_temp_lag_24': False, 'use_temp_lag_48': False, 'use_temp_min': True, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': True, 'h1_kernel_rate_l1': 1.2097653025591597, 'neurons_1': 134, 'activation_1': 'relu', 'regularize_h2_activation': False, 'regularize_h2_kernel': False, 'neurons_2': 114, 'activation_2': 'elu', 'learning_rate': 0.00010889107872167651}. Best is trial 1 with value: 0.10548137128353119.\n",
            "[I 2024-08-27 22:08:40,796] Trial 5 finished with value: 0.17309273779392242 and parameters: {'use_temp_actual': False, 'use_hour': False, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': True, 'use_Rolling_Avg_15': True, 'use_Rolling_Std_15': False, 'use_Rolling_Sum_15': True, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': False, 'use_Rolling_Std_30': True, 'use_temp_lag_1': False, 'use_temp_lag_2': True, 'use_temp_lag_3': True, 'use_temp_mean_6': False, 'use_temp_mean_24': True, 'use_temp_lag_24': False, 'use_temp_lag_48': False, 'use_temp_min': True, 'use_temp_max': False, 'use_HDD': True, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 52, 'activation_1': 'sigmoid', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 1.5546280858331444e-05, 'neurons_2': 49, 'activation_2': 'softmax', 'learning_rate': 0.0001776800989490347}. Best is trial 1 with value: 0.10548137128353119.\n",
            "[I 2024-08-27 22:11:35,290] Trial 6 finished with value: 0.2002907693386078 and parameters: {'use_temp_actual': True, 'use_hour': False, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': True, 'use_Rolling_Avg_15': True, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': False, 'use_Rolling_Std_30': True, 'use_temp_lag_1': False, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': False, 'use_temp_mean_24': True, 'use_temp_lag_24': False, 'use_temp_lag_48': False, 'use_temp_min': True, 'use_temp_max': True, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': True, 'regularize_h1_kernel': False, 'h1_activation_rate_l1': 9.65784425325573e-05, 'neurons_1': 164, 'activation_1': 'elu', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 1.80946501817834e-05, 'h2_kernel_rate_l1': 0.00021603819489158483, 'neurons_2': 92, 'activation_2': 'relu', 'learning_rate': 7.10579703598318e-05}. Best is trial 1 with value: 0.10548137128353119.\n",
            "[I 2024-08-27 22:12:05,467] Trial 7 finished with value: 0.18586619198322296 and parameters: {'use_temp_actual': True, 'use_hour': False, 'use_day_of_week': False, 'use_month': False, 'use_load_lag_198': False, 'use_load_lag_336': True, 'use_load_lag_504': True, 'use_Rolling_Avg_15': True, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': False, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': False, 'use_temp_lag_48': True, 'use_temp_min': True, 'use_temp_max': False, 'use_HDD': True, 'use_CDD': False, 'dropout': True, 'dropout_rate': 0.280111577874939, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 207, 'activation_1': 'relu', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.39147549472117776, 'h2_kernel_rate_l1': 1.451314691964035, 'neurons_2': 18, 'activation_2': 'tanh', 'learning_rate': 0.06402083499829507}. Best is trial 1 with value: 0.10548137128353119.\n",
            "[I 2024-08-27 22:14:50,789] Trial 8 finished with value: 0.38428446650505066 and parameters: {'use_temp_actual': True, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': True, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': True, 'use_temp_lag_3': True, 'use_temp_mean_6': False, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': True, 'use_temp_min': True, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': False, 'dropout': True, 'dropout_rate': 0.5129486369616284, 'regularize_h1_activation': True, 'regularize_h1_kernel': False, 'h1_activation_rate_l1': 3.4726888404187277, 'neurons_1': 102, 'activation_1': 'sigmoid', 'regularize_h2_activation': True, 'regularize_h2_kernel': False, 'h2_activation_rate_l1': 4.469592395876073, 'neurons_2': 167, 'activation_2': 'relu', 'learning_rate': 0.001491557868037373}. Best is trial 1 with value: 0.10548137128353119.\n",
            "[I 2024-08-27 22:15:13,095] Trial 9 finished with value: 0.23010706901550293 and parameters: {'use_temp_actual': False, 'use_hour': False, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': False, 'use_load_lag_336': False, 'use_load_lag_504': True, 'use_Rolling_Avg_15': True, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': True, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': False, 'use_Rolling_Std_30': False, 'use_temp_lag_1': False, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': False, 'use_temp_lag_48': True, 'use_temp_min': True, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': True, 'dropout': True, 'dropout_rate': 0.2851423384106102, 'regularize_h1_activation': False, 'regularize_h1_kernel': True, 'h1_kernel_rate_l1': 0.0005538887593733475, 'neurons_1': 201, 'activation_1': 'softmax', 'regularize_h2_activation': False, 'regularize_h2_kernel': False, 'neurons_2': 86, 'activation_2': 'softplus', 'learning_rate': 0.04198237700526212}. Best is trial 1 with value: 0.10548137128353119.\n",
            "[I 2024-08-27 22:15:39,841] Trial 10 finished with value: 306.9237060546875 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': False, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': False, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': True, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': False, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': True, 'regularize_h1_kernel': False, 'h1_activation_rate_l1': 0.8772117861788223, 'neurons_1': 17, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.006036053167122596, 'neurons_2': 238, 'activation_2': 'softmax', 'learning_rate': 0.0065921201297175335}. Best is trial 1 with value: 0.10548137128353119.\n",
            "[I 2024-08-27 22:18:28,109] Trial 11 finished with value: 0.17331016063690186 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': False, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': False, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 190, 'activation_1': 'elu', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0018106677659891074, 'h2_kernel_rate_l1': 0.0063165256951707984, 'neurons_2': 181, 'activation_2': 'sigmoid', 'learning_rate': 1.0089274810139627e-05}. Best is trial 1 with value: 0.10548137128353119.\n",
            "[I 2024-08-27 22:21:08,885] Trial 12 finished with value: 0.23445774614810944 and parameters: {'use_temp_actual': False, 'use_hour': False, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': False, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': False, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 134, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': False, 'h2_activation_rate_l1': 0.009094667694491833, 'neurons_2': 252, 'activation_2': 'softplus', 'learning_rate': 1.355058773842978e-05}. Best is trial 1 with value: 0.10548137128353119.\n",
            "[I 2024-08-27 22:23:51,226] Trial 13 finished with value: 0.11983323097229004 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': False, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 228, 'activation_1': 'elu', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 1.2162819271730796, 'neurons_2': 191, 'activation_2': 'softplus', 'learning_rate': 0.0008756600704089962}. Best is trial 1 with value: 0.10548137128353119.\n",
            "[I 2024-08-27 22:25:35,990] Trial 14 finished with value: 0.12431567907333374 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 231, 'activation_1': 'softmax', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 5.6912970492562485, 'neurons_2': 207, 'activation_2': 'softmax', 'learning_rate': 0.0009020627913433306}. Best is trial 1 with value: 0.10548137128353119.\n",
            "[I 2024-08-27 22:28:28,184] Trial 15 finished with value: 0.19802211225032806 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': False, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': False, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': False, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 220, 'activation_1': 'softplus', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.15063158782496952, 'neurons_2': 217, 'activation_2': 'sigmoid', 'learning_rate': 0.0008333409273662789}. Best is trial 1 with value: 0.10548137128353119.\n",
            "[I 2024-08-27 22:30:24,373] Trial 16 finished with value: 0.08922462910413742 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': False, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 256, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.0008576114653619121, 'neurons_2': 152, 'activation_2': 'softplus', 'learning_rate': 0.00887484220071634}. Best is trial 16 with value: 0.08922462910413742.\n",
            "[I 2024-08-27 22:32:10,510] Trial 17 finished with value: 0.08013366162776947 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 253, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.0004014262466381012, 'neurons_2': 149, 'activation_2': 'softmax', 'learning_rate': 0.02173668143498728}. Best is trial 17 with value: 0.08013366162776947.\n",
            "[I 2024-08-27 22:32:27,266] Trial 18 finished with value: 1867.1181640625 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': False, 'use_month': False, 'use_load_lag_198': False, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': False, 'use_Rolling_Sum_15': True, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': True, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': False, 'use_temp_lag_24': True, 'use_temp_lag_48': True, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': False, 'use_CDD': True, 'dropout': True, 'dropout_rate': 0.9985507643806986, 'regularize_h1_activation': True, 'regularize_h1_kernel': True, 'h1_activation_rate_l1': 0.019887692779879246, 'h1_kernel_rate_l1': 1.4051234573280496e-05, 'neurons_1': 83, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.0004496331252586712, 'neurons_2': 151, 'activation_2': 'softmax', 'learning_rate': 0.021338192625480548}. Best is trial 17 with value: 0.08013366162776947.\n",
            "[I 2024-08-27 22:34:04,580] Trial 19 finished with value: 0.08933637291193008 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 163, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 2.5375453608261172e-05, 'neurons_2': 131, 'activation_2': 'softplus', 'learning_rate': 0.01483003051329194}. Best is trial 17 with value: 0.08013366162776947.\n",
            "[I 2024-08-27 22:34:48,694] Trial 20 finished with value: 0.10506686568260193 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': False, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 256, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.03099525512422022, 'neurons_2': 149, 'activation_2': 'sigmoid', 'learning_rate': 0.09883010666970472}. Best is trial 17 with value: 0.08013366162776947.\n",
            "[I 2024-08-27 22:37:08,282] Trial 21 finished with value: 0.08575013279914856 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 157, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 1.262303358852512e-05, 'neurons_2': 133, 'activation_2': 'softplus', 'learning_rate': 0.014126544419739281}. Best is trial 17 with value: 0.08013366162776947.\n",
            "[I 2024-08-27 22:38:54,319] Trial 22 finished with value: 0.09247849881649017 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 105, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 7.251548310206838e-05, 'neurons_2': 134, 'activation_2': 'softplus', 'learning_rate': 0.012305458253071342}. Best is trial 17 with value: 0.08013366162776947.\n",
            "[I 2024-08-27 22:40:28,422] Trial 23 finished with value: 0.07956967502832413 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 217, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.0016197164564618833, 'neurons_2': 164, 'activation_2': 'softplus', 'learning_rate': 0.032718753136487984}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 22:41:55,491] Trial 24 finished with value: 0.08953890949487686 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 151, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.001964782370283534, 'neurons_2': 176, 'activation_2': 'softplus', 'learning_rate': 0.030722310362389354}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 22:44:42,996] Trial 25 finished with value: 0.08768345415592194 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 201, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 7.434477510649046e-05, 'neurons_2': 75, 'activation_2': 'tanh', 'learning_rate': 0.0035225427959629527}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 22:45:26,221] Trial 26 finished with value: 76.59811401367188 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': False, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': False, 'use_temp_mean_24': False, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': True, 'regularize_h1_kernel': True, 'h1_activation_rate_l1': 0.033195666277812744, 'h1_kernel_rate_l1': 9.05450794069535, 'neurons_1': 214, 'activation_1': 'sigmoid', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.03475416632476685, 'neurons_2': 200, 'activation_2': 'relu', 'learning_rate': 0.048287934128505676}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 22:47:01,910] Trial 27 finished with value: 0.17127536237239838 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': False, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': True, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': True, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': True, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': False, 'use_CDD': True, 'dropout': True, 'dropout_rate': 0.02769523794417894, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 184, 'activation_1': 'softmax', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 7.597392648664668e-05, 'neurons_2': 125, 'activation_2': 'elu', 'learning_rate': 0.022498442909967758}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 22:47:31,752] Trial 28 finished with value: 0.13075192272663116 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 228, 'activation_1': 'relu', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 1.034681658202741e-05, 'neurons_2': 164, 'activation_2': 'softmax', 'learning_rate': 0.09484558228244887}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 22:48:01,754] Trial 29 finished with value: 0.24725958704948425 and parameters: {'use_temp_actual': True, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': False, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': True, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': True, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': False, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': False, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': True, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': True, 'regularize_h1_kernel': True, 'h1_activation_rate_l1': 1.6408415450717918e-05, 'h1_kernel_rate_l1': 0.0015409290236000092, 'neurons_1': 120, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.0019982452443217174, 'neurons_2': 120, 'activation_2': 'tanh', 'learning_rate': 0.002884312263597443}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 22:48:52,393] Trial 30 finished with value: 0.13467314839363098 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 151, 'activation_1': 'softplus', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.00017049023594477674, 'neurons_2': 146, 'activation_2': 'softplus', 'learning_rate': 0.012898749534888444}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 22:51:30,577] Trial 31 finished with value: 0.09317926317453384 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 199, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 6.02416752676646e-05, 'neurons_2': 60, 'activation_2': 'tanh', 'learning_rate': 0.0037516755967637646}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 22:54:06,514] Trial 32 finished with value: 0.08308982104063034 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 238, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 3.120105562955899e-05, 'neurons_2': 71, 'activation_2': 'tanh', 'learning_rate': 0.007835651375912188}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 22:56:05,022] Trial 33 finished with value: 0.08515237271785736 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 241, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 3.695615855672778e-05, 'neurons_2': 22, 'activation_2': 'tanh', 'learning_rate': 0.007575630082500017}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 22:58:56,196] Trial 34 finished with value: 0.14330507814884186 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 235, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.0016388683522130143, 'neurons_2': 17, 'activation_2': 'tanh', 'learning_rate': 0.000380082565808309}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 23:00:40,408] Trial 35 finished with value: 0.09454456716775894 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': False, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 248, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': False, 'neurons_2': 34, 'activation_2': 'tanh', 'learning_rate': 0.007014921381911983}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 23:02:48,094] Trial 36 finished with value: 0.14189444482326508 and parameters: {'use_temp_actual': True, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': True, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': False, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': True, 'h1_kernel_rate_l1': 2.346949050103438e-05, 'neurons_1': 241, 'activation_1': 'softplus', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.00021161772254547, 'neurons_2': 101, 'activation_2': 'tanh', 'learning_rate': 0.0019147493701623063}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 23:03:07,759] Trial 37 finished with value: 0.30658626556396484 and parameters: {'use_temp_actual': False, 'use_hour': False, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': True, 'use_Rolling_Avg_15': True, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': True, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': False, 'use_Rolling_Std_30': True, 'use_temp_lag_1': False, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': False, 'use_temp_mean_24': True, 'use_temp_lag_24': False, 'use_temp_lag_48': False, 'use_temp_min': True, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': True, 'dropout_rate': 0.6989540002057384, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 219, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': False, 'neurons_2': 67, 'activation_2': 'elu', 'learning_rate': 0.024938169775749124}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 23:04:25,523] Trial 38 finished with value: 0.10408775508403778 and parameters: {'use_temp_actual': True, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': False, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': False, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 241, 'activation_1': 'relu', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 3.5393982342153014e-05, 'h2_kernel_rate_l1': 3.472026914366418e-05, 'neurons_2': 36, 'activation_2': 'tanh', 'learning_rate': 0.0054868849460144725}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 23:05:29,845] Trial 39 finished with value: 0.18147526681423187 and parameters: {'use_temp_actual': False, 'use_hour': False, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': True, 'use_Rolling_Avg_15': True, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': False, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': False, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': True, 'use_temp_max': True, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': True, 'regularize_h1_kernel': False, 'h1_activation_rate_l1': 0.0009826812010384092, 'neurons_1': 176, 'activation_1': 'sigmoid', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.0004235677782360238, 'neurons_2': 104, 'activation_2': 'softmax', 'learning_rate': 0.04070662762363239}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 23:07:35,831] Trial 40 finished with value: 0.2688673138618469 and parameters: {'use_temp_actual': True, 'use_hour': True, 'use_day_of_week': False, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': False, 'use_temp_lag_2': True, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': False, 'use_temp_lag_24': False, 'use_temp_lag_48': True, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': True, 'dropout_rate': 0.09264265670543859, 'regularize_h1_activation': False, 'regularize_h1_kernel': True, 'h1_kernel_rate_l1': 0.007964281609178973, 'neurons_1': 212, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': False, 'h2_activation_rate_l1': 0.0003997645504075867, 'neurons_2': 51, 'activation_2': 'tanh', 'learning_rate': 4.7553341753641313e-05}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 23:09:46,232] Trial 41 finished with value: 0.08270840346813202 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 245, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 2.4357037380127392e-05, 'neurons_2': 81, 'activation_2': 'softplus', 'learning_rate': 0.01019597515179976}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 23:11:12,488] Trial 42 finished with value: 0.09015300124883652 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 244, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 3.855733232496279e-05, 'neurons_2': 80, 'activation_2': 'relu', 'learning_rate': 0.010726571847769357}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 23:13:04,010] Trial 43 finished with value: 0.08072420209646225 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 229, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.00014748091216269267, 'neurons_2': 31, 'activation_2': 'softmax', 'learning_rate': 0.01736752399259173}. Best is trial 23 with value: 0.07956967502832413.\n",
            "[I 2024-08-27 23:14:26,658] Trial 44 finished with value: 0.07865271717309952 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': True, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': True, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 222, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.00016403525193901504, 'neurons_2': 92, 'activation_2': 'softmax', 'learning_rate': 0.06239082433018902}. Best is trial 44 with value: 0.07865271717309952.\n",
            "[I 2024-08-27 23:16:18,325] Trial 45 finished with value: 0.10380951315164566 and parameters: {'use_temp_actual': False, 'use_hour': False, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': True, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': True, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 221, 'activation_1': 'elu', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.00016886596699780892, 'neurons_2': 91, 'activation_2': 'softmax', 'learning_rate': 0.05500319472434401}. Best is trial 44 with value: 0.07865271717309952.\n",
            "[I 2024-08-27 23:16:40,306] Trial 46 finished with value: 0.12925739586353302 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': False, 'use_load_lag_336': False, 'use_load_lag_504': True, 'use_Rolling_Avg_15': True, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': True, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': False, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': True, 'use_temp_max': False, 'use_HDD': True, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 190, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.07624212698681787, 'h2_kernel_rate_l1': 0.0007254809458693298, 'neurons_2': 166, 'activation_2': 'softmax', 'learning_rate': 0.06481107380815665}. Best is trial 44 with value: 0.07865271717309952.\n",
            "[I 2024-08-27 23:17:58,124] Trial 47 finished with value: 0.11265510320663452 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': True, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': False, 'use_temp_lag_48': False, 'use_temp_min': True, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 206, 'activation_1': 'softmax', 'regularize_h2_activation': False, 'regularize_h2_kernel': False, 'neurons_2': 118, 'activation_2': 'softmax', 'learning_rate': 0.03283049297520027}. Best is trial 44 with value: 0.07865271717309952.\n",
            "[I 2024-08-27 23:18:21,429] Trial 48 finished with value: 0.5459567904472351 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': False, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': True, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': False, 'use_temp_lag_2': True, 'use_temp_lag_3': False, 'use_temp_mean_6': False, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': True, 'use_temp_min': True, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': True, 'dropout_rate': 0.7356355771538678, 'regularize_h1_activation': True, 'regularize_h1_kernel': False, 'h1_activation_rate_l1': 0.16471752142413798, 'neurons_1': 226, 'activation_1': 'relu', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.0003151030817017083, 'neurons_2': 58, 'activation_2': 'softmax', 'learning_rate': 0.018917094543317896}. Best is trial 44 with value: 0.07865271717309952.\n",
            "[I 2024-08-27 23:19:30,383] Trial 49 finished with value: 0.10933355987071991 and parameters: {'use_temp_actual': True, 'use_hour': False, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': True, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': True, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 175, 'activation_1': 'sigmoid', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.0038301368957843213, 'neurons_2': 39, 'activation_2': 'softmax', 'learning_rate': 0.07241308713029625}. Best is trial 44 with value: 0.07865271717309952.\n",
            "[I 2024-08-27 23:19:55,211] Trial 50 finished with value: 0.16855642199516296 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': True, 'use_Rolling_Avg_15': True, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': False, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': False, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': True, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': True, 'h1_kernel_rate_l1': 0.00021447007349159242, 'neurons_1': 55, 'activation_1': 'elu', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.00014222655539267653, 'neurons_2': 102, 'activation_2': 'softmax', 'learning_rate': 0.034917916500470415}. Best is trial 44 with value: 0.07865271717309952.\n",
            "[I 2024-08-27 23:22:10,058] Trial 51 finished with value: 0.07570058852434158 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 233, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 2.0392717662654626e-05, 'neurons_2': 70, 'activation_2': 'softmax', 'learning_rate': 0.020550566054028146}. Best is trial 51 with value: 0.07570058852434158.\n",
            "[I 2024-08-27 23:23:18,308] Trial 52 finished with value: 0.08706830441951752 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 251, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 1.842790408614531e-05, 'neurons_2': 87, 'activation_2': 'softmax', 'learning_rate': 0.018141168814593718}. Best is trial 51 with value: 0.07570058852434158.\n",
            "[I 2024-08-27 23:25:24,819] Trial 53 finished with value: 0.07802598923444748 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': False, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 230, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.00113836952101242, 'neurons_2': 113, 'activation_2': 'softmax', 'learning_rate': 0.027100620548801854}. Best is trial 51 with value: 0.07570058852434158.\n",
            "[I 2024-08-27 23:26:55,739] Trial 54 finished with value: 0.07696875929832458 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': False, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': True, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': False, 'use_CDD': True, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 232, 'activation_1': 'tanh', 'regularize_h2_activation': False, 'regularize_h2_kernel': True, 'h2_kernel_rate_l1': 0.0007812443887935197, 'neurons_2': 140, 'activation_2': 'softmax', 'learning_rate': 0.028498545452006595}. Best is trial 51 with value: 0.07570058852434158.\n",
            "[I 2024-08-27 23:28:25,614] Trial 55 finished with value: 0.06638423353433609 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 212, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0003350912231390067, 'h2_kernel_rate_l1': 0.0012975349734926837, 'neurons_2': 111, 'activation_2': 'softmax', 'learning_rate': 0.04583562349118644}. Best is trial 55 with value: 0.06638423353433609.\n",
            "[I 2024-08-27 23:29:22,023] Trial 56 finished with value: 0.08760552108287811 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': True, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': False, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': True, 'use_temp_max': False, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 194, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.00022242514450741612, 'h2_kernel_rate_l1': 0.00857534843279267, 'neurons_2': 111, 'activation_2': 'softmax', 'learning_rate': 0.06871540435941745}. Best is trial 55 with value: 0.06638423353433609.\n",
            "[I 2024-08-27 23:30:37,490] Trial 57 finished with value: 0.116057388484478 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': False, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': True, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 213, 'activation_1': 'softplus', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.00019705002141593065, 'h2_kernel_rate_l1': 0.001252049885250372, 'neurons_2': 113, 'activation_2': 'softmax', 'learning_rate': 0.0465790806947637}. Best is trial 55 with value: 0.06638423353433609.\n",
            "[I 2024-08-27 23:32:17,967] Trial 58 finished with value: 0.07361465692520142 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': False, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': False, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': False, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 206, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': False, 'h2_activation_rate_l1': 0.0025503711066133306, 'neurons_2': 141, 'activation_2': 'sigmoid', 'learning_rate': 0.028330363246181694}. Best is trial 55 with value: 0.06638423353433609.\n",
            "[I 2024-08-27 23:32:40,851] Trial 59 finished with value: 53558.6171875 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': False, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': False, 'use_temp_lag_2': True, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': False, 'use_temp_lag_48': True, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': True, 'use_CDD': False, 'dropout': True, 'dropout_rate': 0.4710910957091963, 'regularize_h1_activation': True, 'regularize_h1_kernel': False, 'h1_activation_rate_l1': 8.900579146660167, 'neurons_1': 202, 'activation_1': 'softmax', 'regularize_h2_activation': True, 'regularize_h2_kernel': False, 'h2_activation_rate_l1': 0.0041526508782478155, 'neurons_2': 143, 'activation_2': 'sigmoid', 'learning_rate': 0.028225719109997657}. Best is trial 55 with value: 0.06638423353433609.\n",
            "[I 2024-08-27 23:33:56,362] Trial 60 finished with value: 0.13652990758419037 and parameters: {'use_temp_actual': False, 'use_hour': False, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': False, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': False, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': False, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': False, 'use_temp_lag_24': False, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 233, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': False, 'h2_activation_rate_l1': 0.0009398412353237927, 'neurons_2': 96, 'activation_2': 'sigmoid', 'learning_rate': 0.08060064447543931}. Best is trial 55 with value: 0.06638423353433609.\n",
            "[I 2024-08-27 23:35:00,044] Trial 61 finished with value: 0.08168963342905045 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': False, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': False, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': False, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 221, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': False, 'h2_activation_rate_l1': 0.05296507489662411, 'neurons_2': 162, 'activation_2': 'sigmoid', 'learning_rate': 0.03984328078771542}. Best is trial 55 with value: 0.06638423353433609.\n",
            "[I 2024-08-27 23:35:48,548] Trial 62 finished with value: 0.09359798580408096 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': False, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': False, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': False, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 210, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': False, 'h2_activation_rate_l1': 0.00016925655749971423, 'neurons_2': 139, 'activation_2': 'softmax', 'learning_rate': 0.05254786546710158}. Best is trial 55 with value: 0.06638423353433609.\n",
            "[I 2024-08-27 23:36:53,623] Trial 63 finished with value: 0.08557451516389847 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': False, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': False, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': False, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 188, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': False, 'h2_activation_rate_l1': 6.978504636119492e-05, 'neurons_2': 131, 'activation_2': 'sigmoid', 'learning_rate': 0.03365713838856517}. Best is trial 55 with value: 0.06638423353433609.\n",
            "[I 2024-08-27 23:38:03,572] Trial 64 finished with value: 0.07377123832702637 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 217, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.03828200976353846, 'h2_kernel_rate_l1': 0.0038614020578402243, 'neurons_2': 158, 'activation_2': 'elu', 'learning_rate': 0.09926976700852816}. Best is trial 55 with value: 0.06638423353433609.\n",
            "[I 2024-08-27 23:39:09,078] Trial 65 finished with value: 0.07994627207517624 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 225, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.05312026391820446, 'h2_kernel_rate_l1': 0.003816989235182428, 'neurons_2': 125, 'activation_2': 'elu', 'learning_rate': 0.07952762664386}. Best is trial 55 with value: 0.06638423353433609.\n",
            "[I 2024-08-27 23:40:14,148] Trial 66 finished with value: 0.08025308698415756 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': False, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': True, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': False, 'use_temp_mean_6': False, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': False, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 182, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.25445298998461313, 'h2_kernel_rate_l1': 0.01970635139778347, 'neurons_2': 154, 'activation_2': 'elu', 'learning_rate': 0.05587000193198651}. Best is trial 55 with value: 0.06638423353433609.\n",
            "[I 2024-08-27 23:42:08,807] Trial 67 finished with value: 0.06822589784860611 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 234, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.001954909741482885, 'h2_kernel_rate_l1': 0.0037183468213698814, 'neurons_2': 181, 'activation_2': 'elu', 'learning_rate': 0.024041279491145102}. Best is trial 55 with value: 0.06638423353433609.\n",
            "[I 2024-08-27 23:43:25,198] Trial 68 finished with value: 0.3531824052333832 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': False, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': False, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': False, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': True, 'h1_kernel_rate_l1': 0.02094404284308381, 'neurons_1': 231, 'activation_1': 'elu', 'regularize_h2_activation': True, 'regularize_h2_kernel': False, 'h2_activation_rate_l1': 0.0011267077649293794, 'neurons_2': 181, 'activation_2': 'elu', 'learning_rate': 0.02455137687320987}. Best is trial 55 with value: 0.06638423353433609.\n",
            "[I 2024-08-27 23:45:02,858] Trial 69 finished with value: 0.08263920247554779 and parameters: {'use_temp_actual': True, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': False, 'use_Rolling_Sum_15': True, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 206, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0121917389615989, 'h2_kernel_rate_l1': 0.08074032510150965, 'neurons_2': 191, 'activation_2': 'elu', 'learning_rate': 0.09563820826385429}. Best is trial 55 with value: 0.06638423353433609.\n",
            "[I 2024-08-27 23:46:11,361] Trial 70 finished with value: 0.20261125266551971 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': True, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': False, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': True, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': True, 'regularize_h1_kernel': False, 'h1_activation_rate_l1': 0.0017854705412945584, 'neurons_1': 199, 'activation_1': 'relu', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.003910173215418573, 'h2_kernel_rate_l1': 0.0034757071577554105, 'neurons_2': 174, 'activation_2': 'elu', 'learning_rate': 0.0006346751269441159}. Best is trial 55 with value: 0.06638423353433609.\n",
            "[I 2024-08-27 23:48:22,268] Trial 71 finished with value: 0.0638718530535698 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 237, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0005886196286493923, 'h2_kernel_rate_l1': 0.000792878893830565, 'neurons_2': 125, 'activation_2': 'elu', 'learning_rate': 0.015753515348861588}. Best is trial 71 with value: 0.0638718530535698.\n",
            "[I 2024-08-27 23:50:29,901] Trial 72 finished with value: 0.06409573554992676 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 235, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0006208522117004191, 'h2_kernel_rate_l1': 0.01586603339260264, 'neurons_2': 157, 'activation_2': 'elu', 'learning_rate': 0.014792996495419639}. Best is trial 71 with value: 0.0638718530535698.\n",
            "[I 2024-08-27 23:52:32,266] Trial 73 finished with value: 0.06514940410852432 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 255, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0006164820417229071, 'h2_kernel_rate_l1': 0.015512383851006735, 'neurons_2': 228, 'activation_2': 'elu', 'learning_rate': 0.01610824460432859}. Best is trial 71 with value: 0.0638718530535698.\n",
            "[I 2024-08-27 23:54:17,338] Trial 74 finished with value: 0.06979045271873474 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 254, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.00063146020384453, 'h2_kernel_rate_l1': 0.013186260186126987, 'neurons_2': 218, 'activation_2': 'elu', 'learning_rate': 0.015192201034879279}. Best is trial 71 with value: 0.0638718530535698.\n",
            "[I 2024-08-27 23:56:30,032] Trial 75 finished with value: 0.07142255455255508 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 256, 'activation_1': 'sigmoid', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0006316975326504421, 'h2_kernel_rate_l1': 0.0170457311415297, 'neurons_2': 234, 'activation_2': 'elu', 'learning_rate': 0.01356722968009344}. Best is trial 71 with value: 0.0638718530535698.\n",
            "[I 2024-08-27 23:59:15,445] Trial 76 finished with value: 0.0826423168182373 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 255, 'activation_1': 'sigmoid', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0005842860596675782, 'h2_kernel_rate_l1': 0.01412590375756129, 'neurons_2': 219, 'activation_2': 'elu', 'learning_rate': 0.004976203955219224}. Best is trial 71 with value: 0.0638718530535698.\n",
            "[I 2024-08-27 23:59:36,002] Trial 77 finished with value: 0.2746930718421936 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': True, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': False, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': True, 'dropout_rate': 0.7326586812742841, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 246, 'activation_1': 'sigmoid', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.002308374000041048, 'h2_kernel_rate_l1': 0.06581365035240404, 'neurons_2': 241, 'activation_2': 'elu', 'learning_rate': 0.012307542904611755}. Best is trial 71 with value: 0.0638718530535698.\n",
            "[I 2024-08-28 00:02:13,167] Trial 78 finished with value: 0.07589273154735565 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': False, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': False, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 251, 'activation_1': 'sigmoid', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0005106716607465997, 'h2_kernel_rate_l1': 0.2075765863353398, 'neurons_2': 221, 'activation_2': 'elu', 'learning_rate': 0.015579320000939789}. Best is trial 71 with value: 0.0638718530535698.\n",
            "[I 2024-08-28 00:02:44,793] Trial 79 finished with value: 39.00019836425781 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': True, 'h1_kernel_rate_l1': 9.977121778410707, 'neurons_1': 241, 'activation_1': 'sigmoid', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0007429210592285443, 'h2_kernel_rate_l1': 0.007162440123789175, 'neurons_2': 229, 'activation_2': 'elu', 'learning_rate': 0.011208541406237648}. Best is trial 71 with value: 0.0638718530535698.\n",
            "[I 2024-08-28 00:05:29,516] Trial 80 finished with value: 0.10760647803544998 and parameters: {'use_temp_actual': True, 'use_hour': False, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': False, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': False, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 256, 'activation_1': 'softplus', 'regularize_h2_activation': True, 'regularize_h2_kernel': False, 'h2_activation_rate_l1': 0.0002975304027196764, 'neurons_2': 245, 'activation_2': 'elu', 'learning_rate': 0.003542505853819224}. Best is trial 71 with value: 0.0638718530535698.\n",
            "[I 2024-08-28 00:08:22,777] Trial 81 finished with value: 0.06340339779853821 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 237, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0013893818438462007, 'h2_kernel_rate_l1': 0.014283805430533092, 'neurons_2': 204, 'activation_2': 'elu', 'learning_rate': 0.009355263428102242}. Best is trial 81 with value: 0.06340339779853821.\n",
            "[I 2024-08-28 00:11:02,866] Trial 82 finished with value: 0.060036759823560715 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 238, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.002183364309811904, 'h2_kernel_rate_l1': 0.014619674726375919, 'neurons_2': 209, 'activation_2': 'elu', 'learning_rate': 0.008633292204680593}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:13:53,927] Trial 83 finished with value: 0.0641438439488411 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 247, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0012201421005667754, 'h2_kernel_rate_l1': 0.023400321039529822, 'neurons_2': 211, 'activation_2': 'elu', 'learning_rate': 0.005467544763137376}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:16:21,471] Trial 84 finished with value: 0.06502366811037064 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 237, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.001309077621356889, 'h2_kernel_rate_l1': 0.03322678058474798, 'neurons_2': 205, 'activation_2': 'elu', 'learning_rate': 0.008880405266437219}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:18:15,536] Trial 85 finished with value: 0.07430891692638397 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 237, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0020002043721563368, 'h2_kernel_rate_l1': 0.02610483333317369, 'neurons_2': 203, 'activation_2': 'elu', 'learning_rate': 0.005645937068832942}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:20:04,793] Trial 86 finished with value: 0.08778644353151321 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': False, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': True, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 247, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0012273699297162294, 'h2_kernel_rate_l1': 0.03599642014928021, 'neurons_2': 194, 'activation_2': 'elu', 'learning_rate': 0.009797532735574845}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:22:02,441] Trial 87 finished with value: 0.09237425774335861 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': True, 'use_Rolling_Std_15': False, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': False, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 240, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.005745754014659808, 'h2_kernel_rate_l1': 0.061136004017809505, 'neurons_2': 212, 'activation_2': 'elu', 'learning_rate': 0.008183037818529606}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:25:00,012] Trial 88 finished with value: 0.16049697995185852 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': True, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': True, 'regularize_h1_kernel': False, 'h1_activation_rate_l1': 1.1583569420288716e-05, 'neurons_1': 247, 'activation_1': 'softmax', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.00012079366138184306, 'h2_kernel_rate_l1': 0.2120624011984301, 'neurons_2': 226, 'activation_2': 'elu', 'learning_rate': 0.0023487245499384194}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:25:29,102] Trial 89 finished with value: 0.14915813505649567 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': True, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': True, 'dropout_rate': 0.24137844378183893, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 236, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0015730391257981593, 'h2_kernel_rate_l1': 0.010573664261671625, 'neurons_2': 209, 'activation_2': 'relu', 'learning_rate': 0.006314781173757589}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:28:22,145] Trial 90 finished with value: 0.07446388900279999 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': False, 'use_temp_mean_24': False, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 224, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0003958562581036986, 'h2_kernel_rate_l1': 0.005995114200655253, 'neurons_2': 197, 'activation_2': 'elu', 'learning_rate': 0.00408802737714733}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:31:07,129] Trial 91 finished with value: 0.06236758455634117 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 249, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.001042196017050301, 'h2_kernel_rate_l1': 0.012262704594561503, 'neurons_2': 187, 'activation_2': 'elu', 'learning_rate': 0.008332907747774137}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:33:19,144] Trial 92 finished with value: 0.06465205550193787 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 244, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0012183727220967193, 'h2_kernel_rate_l1': 0.0423816376007615, 'neurons_2': 203, 'activation_2': 'elu', 'learning_rate': 0.008808483502744498}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:36:25,217] Trial 93 finished with value: 0.09249831736087799 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 247, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0009859201544138532, 'h2_kernel_rate_l1': 0.04318038091089073, 'neurons_2': 213, 'activation_2': 'elu', 'learning_rate': 0.0013067371617898958}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:39:00,545] Trial 94 finished with value: 0.06348223984241486 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 243, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0003290334248893497, 'h2_kernel_rate_l1': 0.02238068917578464, 'neurons_2': 205, 'activation_2': 'elu', 'learning_rate': 0.008784679039897856}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:41:56,815] Trial 95 finished with value: 0.07890896499156952 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 242, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0011409871335411538, 'h2_kernel_rate_l1': 0.0945157324268902, 'neurons_2': 186, 'activation_2': 'elu', 'learning_rate': 0.004373077245160896}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:44:13,722] Trial 96 finished with value: 0.06853711605072021 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 237, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.004173684955804622, 'h2_kernel_rate_l1': 0.023486497990754276, 'neurons_2': 204, 'activation_2': 'elu', 'learning_rate': 0.008217440385963368}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:45:41,263] Trial 97 finished with value: 0.13832977414131165 and parameters: {'use_temp_actual': False, 'use_hour': False, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': True, 'h1_kernel_rate_l1': 9.093017812051889e-05, 'neurons_1': 228, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.00032297974145811684, 'h2_kernel_rate_l1': 0.1102310240978799, 'neurons_2': 198, 'activation_2': 'elu', 'learning_rate': 0.006225507493890245}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:47:34,500] Trial 98 finished with value: 0.07099931687116623 and parameters: {'use_temp_actual': True, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 251, 'activation_1': 'relu', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 9.401879311527854e-05, 'h2_kernel_rate_l1': 0.039638403023749685, 'neurons_2': 255, 'activation_2': 'elu', 'learning_rate': 0.009698931511214256}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:50:11,229] Trial 99 finished with value: 0.09635482728481293 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 70, 'activation_1': 'elu', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0028742102098098096, 'h2_kernel_rate_l1': 0.010476182050184692, 'neurons_2': 225, 'activation_2': 'elu', 'learning_rate': 0.00289920620644159}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:53:00,482] Trial 100 finished with value: 0.08979189395904541 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': False, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': True, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': True, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': False, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 244, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0008309856378109236, 'h2_kernel_rate_l1': 0.019826711675602817, 'neurons_2': 190, 'activation_2': 'elu', 'learning_rate': 0.007039847304187555}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:55:23,373] Trial 101 finished with value: 0.06731659173965454 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 250, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.00020762739854508435, 'h2_kernel_rate_l1': 0.05179270545381558, 'neurons_2': 205, 'activation_2': 'elu', 'learning_rate': 0.011648187441742001}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:56:55,102] Trial 102 finished with value: 0.07052718847990036 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 238, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.00045349071180686456, 'h2_kernel_rate_l1': 0.005571604107234441, 'neurons_2': 173, 'activation_2': 'elu', 'learning_rate': 0.017275726249458275}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 00:59:33,732] Trial 103 finished with value: 0.06976482272148132 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 128, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0002989483597773295, 'h2_kernel_rate_l1': 0.025470340703247166, 'neurons_2': 213, 'activation_2': 'relu', 'learning_rate': 0.009152784714531924}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 01:01:42,434] Trial 104 finished with value: 0.0977521613240242 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 28, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.0016919121822459554, 'h2_kernel_rate_l1': 0.010641125943983034, 'neurons_2': 209, 'activation_2': 'elu', 'learning_rate': 0.0049583021462343245}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 01:04:27,211] Trial 105 finished with value: 0.0627807229757309 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 217, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 4.865058670793888e-05, 'h2_kernel_rate_l1': 0.015068822105830335, 'neurons_2': 186, 'activation_2': 'elu', 'learning_rate': 0.013302662297736224}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 01:06:34,514] Trial 106 finished with value: 0.06851283460855484 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 217, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.001221160627764412, 'h2_kernel_rate_l1': 0.016945352701248386, 'neurons_2': 201, 'activation_2': 'elu', 'learning_rate': 0.013263792902478472}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 01:08:56,449] Trial 107 finished with value: 0.2078309804201126 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': False, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': True, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': True, 'regularize_h1_kernel': False, 'h1_activation_rate_l1': 0.2295855450028094, 'neurons_1': 225, 'activation_1': 'softplus', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 1.0722165711807308e-05, 'h2_kernel_rate_l1': 0.029348613445237513, 'neurons_2': 184, 'activation_2': 'elu', 'learning_rate': 0.007150641868890895}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 01:09:14,364] Trial 108 finished with value: 0.20415356755256653 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': True, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': True, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': True, 'dropout_rate': 0.5204651282456357, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 243, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 4.4540775181143685e-05, 'h2_kernel_rate_l1': 0.013890488285390763, 'neurons_2': 170, 'activation_2': 'elu', 'learning_rate': 0.015722331999446424}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 01:11:09,531] Trial 109 finished with value: 0.06410947442054749 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': False, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 231, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 3.4551186362502384e-05, 'h2_kernel_rate_l1': 0.14782131433636078, 'neurons_2': 234, 'activation_2': 'elu', 'learning_rate': 0.021353752288794825}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 01:14:02,782] Trial 110 finished with value: 0.08387471735477448 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': False, 'use_temp_mean_24': False, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 231, 'activation_1': 'softmax', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 3.8246612677624705e-05, 'h2_kernel_rate_l1': 0.3255587999860039, 'neurons_2': 188, 'activation_2': 'elu', 'learning_rate': 0.0087052046906059}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 01:16:21,002] Trial 111 finished with value: 0.06394462287425995 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': False, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 236, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 2.6342010017249037e-05, 'h2_kernel_rate_l1': 0.44402195297065844, 'neurons_2': 231, 'activation_2': 'elu', 'learning_rate': 0.02019832364364009}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 01:18:19,279] Trial 112 finished with value: 0.06526663154363632 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': False, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 227, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 1.0635775314020742e-05, 'h2_kernel_rate_l1': 0.8648808939014027, 'neurons_2': 234, 'activation_2': 'elu', 'learning_rate': 0.019550684235159627}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 01:21:00,122] Trial 113 finished with value: 0.06509049981832504 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': False, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 235, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 1.8516663878767993e-05, 'h2_kernel_rate_l1': 0.29963913431307915, 'neurons_2': 246, 'activation_2': 'elu', 'learning_rate': 0.010977643848134244}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 01:22:14,992] Trial 114 finished with value: 0.08009633421897888 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': False, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 106, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 2.1253052548031313e-05, 'h2_kernel_rate_l1': 0.8272595407490749, 'neurons_2': 196, 'activation_2': 'elu', 'learning_rate': 0.020385506402515914}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 01:24:52,284] Trial 115 finished with value: 0.06481210142374039 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': False, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 238, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 5.978715622680445e-05, 'h2_kernel_rate_l1': 1.946533717307034, 'neurons_2': 221, 'activation_2': 'elu', 'learning_rate': 0.012919589599019576}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 01:27:19,232] Trial 116 finished with value: 0.06554816663265228 and parameters: {'use_temp_actual': False, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': False, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 220, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 6.711858991782951e-05, 'h2_kernel_rate_l1': 6.708302404709751, 'neurons_2': 234, 'activation_2': 'elu', 'learning_rate': 0.012581099297477473}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 01:30:18,900] Trial 117 finished with value: 0.17872631549835205 and parameters: {'use_temp_actual': False, 'use_hour': False, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': False, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': True, 'h1_kernel_rate_l1': 0.002790439623680205, 'neurons_1': 243, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 2.2494329571416587e-05, 'h2_kernel_rate_l1': 0.11528009495264258, 'neurons_2': 224, 'activation_2': 'elu', 'learning_rate': 3.872560313429206e-05}. Best is trial 82 with value: 0.060036759823560715.\n",
            "[I 2024-08-28 01:32:15,459] Trial 118 finished with value: 0.06990761309862137 and parameters: {'use_temp_actual': True, 'use_hour': True, 'use_day_of_week': True, 'use_month': True, 'use_load_lag_198': True, 'use_load_lag_336': True, 'use_load_lag_504': False, 'use_Rolling_Avg_15': False, 'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False, 'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True, 'use_Rolling_Std_30': False, 'use_temp_lag_1': True, 'use_temp_lag_2': False, 'use_temp_lag_3': True, 'use_temp_mean_6': True, 'use_temp_mean_24': False, 'use_temp_lag_24': True, 'use_temp_lag_48': False, 'use_temp_min': False, 'use_temp_max': True, 'use_HDD': True, 'use_CDD': False, 'dropout': False, 'regularize_h1_activation': False, 'regularize_h1_kernel': False, 'neurons_1': 231, 'activation_1': 'tanh', 'regularize_h2_activation': True, 'regularize_h2_kernel': True, 'h2_activation_rate_l1': 5.889687231184591e-05, 'h2_kernel_rate_l1': 3.7348027190537945, 'neurons_2': 216, 'activation_2': 'elu', 'learning_rate': 0.022353229155746092}. Best is trial 82 with value: 0.060036759823560715.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
        "\n",
        "import optuna\n",
        "from tensorflow.keras.layers import Dense, Dropout,BatchNormalization,LayerNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers, Model, Input,regularizers\n",
        "import statistics\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "os.listdir('/content/')\n",
        "file_path = '/content/pythondf.csv'\n",
        "dfload = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#def median_absolute_error(y_true, y_pred):\n",
        " #   error= tfp.stats.percentile(abs(y_true-y_pred), q=50.)\n",
        "  #  return error\n",
        "\n",
        "\n",
        "\n",
        "dfload = dfload.drop(dfload.columns[0], axis=1)\n",
        "# Define a function to add '00:00:00' if time component is missing\n",
        "def add_missing_time_component(date_str):\n",
        "    if len(date_str) == 10:  # Assuming 'YYYY-MM-DD' format\n",
        "        return date_str + ' 00:00:00'\n",
        "    return date_str\n",
        "\n",
        "# Apply the function to the DateTime column\n",
        "dfload['DateTime'] = dfload['DateTime'].apply(add_missing_time_component)\n",
        "\n",
        "# Now convert the DateTime column to datetime format\n",
        "dfload['DateTime'] = pd.to_datetime(dfload['DateTime'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
        "\n",
        "\n",
        "# Convert the datetime column to datetime objects\n",
        "dfload['DateTime'] = pd.to_datetime(dfload['DateTime'])\n",
        "\n",
        "# Extract hour of the day, day of the week, and month of the year\n",
        "dfload['hour'] = dfload['DateTime'].dt.hour\n",
        "dfload['day_of_week'] = dfload['DateTime'].dt.dayofweek  # Monday=0, Sunday=6\n",
        "dfload['month'] = dfload['DateTime'].dt.month\n",
        "\n",
        "# Convert these variables to dummy variables\n",
        "#df_hour_dummies = pd.get_dummies(dfload['hour'], prefix='hour').astype(int)\n",
        "#df_day_dummies = pd.get_dummies(dfload['day_of_week'], prefix='day_of_week').astype(int)\n",
        "#df_month_dummies = pd.get_dummies(dfload['month'], prefix='month').astype(int)\n",
        "\n",
        "\n",
        "\n",
        "# Generate lagged features for temperature\n",
        "for lag in [198,336,504]:\n",
        "    dfload[f'load_lag_{lag}'] = dfload['Load_DA'].shift(lag)\n",
        "\n",
        "dfload[\"Rolling_Avg_15\"] = dfload[\"Load_DA\"].rolling(window=15*24).mean().shift(7*24)\n",
        "dfload[\"Rolling_Std_15\"] = dfload[\"Load_DA\"].rolling(window=15*24).std().shift(7*24)\n",
        "dfload[\"Rolling_Sum_15\"] = dfload[\"Load_DA\"].rolling(window=15*24).sum().shift(7*24)\n",
        "dfload[\"Rolling_Avg_30\"] = dfload[\"Load_DA\"].rolling(window=30*24).mean().shift(7*24)\n",
        "dfload[\"Rolling_Sum_30\"] = dfload[\"Load_DA\"].rolling(window=30*24).sum().shift(7*24)\n",
        "# Calculate the moving standard deviation over the last 30 days, excluding the first 7 days\n",
        "dfload[\"Rolling_Std_30\"] = dfload[\"Load_DA\"].rolling(window=30*24).std().shift(7*24)\n",
        "\n",
        "for lag in range(1, 4):\n",
        "    dfload[f'temp_lag_{lag}'] = dfload['temp_actual'].shift(lag)\n",
        "\n",
        "# Generate rolling mean features for temperature\n",
        "for window in [6,24]:\n",
        "    dfload[f'temp_mean_{window}'] = dfload['temp_actual'].rolling(window=window).mean()\n",
        "\n",
        "# Generate min and max features for temperature over the last 24 hours\n",
        " ##temp_min_24 =  dfload['temp_actual'].rolling(window=24).min()\n",
        "\n",
        " #dfload['temp_max_24'] =  dfload['temp_actual'].rolling(window=24).max()\n",
        "\n",
        "# Generate lag features for temperature at 24, 48, and 96 hours\n",
        "for lag in [24, 48]:\n",
        "     dfload[f'temp_lag_{lag}'] =  dfload['temp_actual'].shift(lag)\n",
        "\n",
        "# Generate lag features for wind speed\n",
        "#for lag in range(1, 8):\n",
        " #    dfload[f'wspd_lag_{lag}'] =  dfload['wspd_actual'].shift(lag)\n",
        "\n",
        "#for lag in range(1, 8):\n",
        " #   dfload[f'dwpt_lag_{lag}'] = dfload['dwpt_actual'].shift(lag)\n",
        "\n",
        "#for lag in range(1, 8):\n",
        "  #dfload[f'pres_lag_{lag}'] = dfload['pres_actual'].shift(lag)\n",
        "\n",
        "#for window in [2,4,8,12,24]:\n",
        " #   dfload[f'dew_mean_{window}'] = dfload['dwpt_actual'].rolling(window=window).mean()\n",
        "# Generate min and max features for temperature over the last 24 hours\n",
        "dfload['temp_min'] =  dfload['temp_actual'].rolling(window=24).min()\n",
        "dfload['temp_max'] =  dfload['temp_actual'].rolling(window=24).max()\n",
        "\n",
        "\n",
        "# Assuming df is your DataFrame with relevant columns\n",
        "\n",
        "# Wind Chill calculation\n",
        "#def calculate_wind_chill(temp, wind_speed):\n",
        " #   # Only calculate wind chill if temperature < 10°C and wind speed > 4.8 km/h\n",
        "  #  wind_chill = np.where(\n",
        "   #     (temp < 10) & (wind_speed > 4.8),\n",
        "    #    13.12 + 0.6215 * temp - 11.37 * (wind_speed ** 0.16) + 0.3965 * temp * (wind_speed ** 0.16),\n",
        "     #   temp\n",
        "    #)\n",
        "    #return wind_chill\n",
        "\n",
        "# Humidity calculation\n",
        "#def calculate_humidity(temp, dew_point):\n",
        " #   humidity = 100 * (np.exp((17.625 * dew_point) / (dew_point + 243.04)) /\n",
        "  #                    np.exp((17.625 * temp) / (temp + 243.04)))\n",
        "   # return humidity\n",
        "\n",
        "# Apply the calculations to the DataFrame\n",
        "#dfload['Wind_Chill'] = calculate_wind_chill(dfload['temp_actual'], dfload['wspd_actual'])\n",
        "#dfload['Humidity'] = calculate_humidity(dfload['temp_actual'], dfload['dwpt_actual'])\n",
        "\n",
        "\n",
        "#for lag in range(1, 6):\n",
        "   # dfload[f'Wind_Chill_L{lag}'] = dfload['Wind_Chill'].shift(lag)\n",
        " #   dfload[f'Humidity_L{lag}'] = dfload['Humidity'].shift(lag)\n",
        "\n",
        "#for window in [4,8,12,24]:\n",
        "    #dfload[f'Wind_Chill_M{window}'] = dfload['Wind_Chill'].rolling(window=window).mean()\n",
        "   # dfload[f'Humidity_M{window}'] = dfload['Humidity'].rolling(window=window).mean()\n",
        "\n",
        "#Example: \"Climate Change and Energy Demand in France\" by Hallegatte et al., which discusses the impact of temperature on energy demand and uses 18°C as a reference for HDD.\n",
        "T_base = 18\n",
        "\n",
        "# Calculate HDD and CDD\n",
        "dfload['HDD'] = dfload['temp_actual'].apply(lambda x: max(0, T_base - x))\n",
        "\n",
        "dfload['CDD'] = dfload['temp_actual'].apply(lambda x: max(0, x - T_base))\n",
        "#for lag in range(1, 8):\n",
        "    #dfload[f'HDD_L{lag}'] = dfload['HDD'].shift(lag)\n",
        "   # dfload[f'CDD_L{lag}'] = dfload['CDD'].shift(lag)\n",
        "#for window in [4,6,8,12,24]:\n",
        " #   dfload[f'HDD_M{window}'] = dfload['HDD'].rolling(window=window).mean()\n",
        "  #  dfload[f'CDD_M{window}'] = dfload['CDD'].rolling(window=window).mean()\n",
        "\n",
        "#dfload['dwpt_min'] =  dfload['dwpt_actual'].rolling(window=24).min()\n",
        "#dfload['dwpt_max'] =  dfload['dwpt_actual'].rolling(window=24).max()\n",
        "#dfload['pres_min'] =  dfload['pres_actual'].rolling(window=24).min()\n",
        "#dfload['pres_max'] =  dfload['pres_actual'].rolling(window=24).max()\n",
        "#fload['wspd_min'] =  dfload['wspd_actual'].rolling(window=24).min()\n",
        "#dfload['wspd_max'] =  dfload['wspd_actual'].rolling(window=24).max()\n",
        "#dfload['HDD_min'] =  dfload['HDD'].rolling(window=24).min()\n",
        "#dfload['HDD_max'] =  dfload['HDD'].rolling(window=24).max()\n",
        "#dfload['CDD_min'] =  dfload['CDD'].rolling(window=24).min()\n",
        "#dfload['CDD_max'] =  dfload['CDD'].rolling(window=24).max()\n",
        "#dfload['Wind_Chill_min'] =  dfload['Wind_Chill'].rolling(window=24).min()\n",
        "#dfload['Wind_Chill_max'] =  dfload['Wind_Chill'].rolling(window=24).max()\n",
        "#dfload['Humidity_min'] =  dfload['Humidity'].rolling(window=24).min()\n",
        "#dfload['Humidity_max'] =  dfload['Humidity'].rolling(window=24).max()\n",
        "\n",
        "# Combine original DataFrame with dummy variables\n",
        "#f_combined = pd.concat([dfload, df_hour_dummies, df_day_dummies, df_month_dummies], axis=1)\n",
        "#f_combined = pd.concat([dfload, df_day_dummies, df_month_dummies], axis=1)\n",
        "#dfload['hourdm'] =pd.get_dummies(dfload['hour'], prefix='hour').astype(int)\n",
        "#f_combined = pd.concat([dfload, df_day_dummies, df_month_dummies], axis=1)\n",
        "dfx = pd.concat([dfload.drop(columns=['dwpt_actual','wspd_actual','pres_actual'])], axis=1)\n",
        "#dfx = pd.concat([f_combined.drop(columns=['month','day_of_week','wspd_actual'])], axis=1)\n",
        "\n",
        "window = slice(8785, 43825)\n",
        "\n",
        "\n",
        "train_val_set = dfx[window]\n",
        "\n",
        "test_set = dfx[43825:]\n",
        "features = train_val_set.drop(columns=['DateTime',\t'Load_DA',\t'Load_Act'])\n",
        "target = train_val_set['Load_DA'].values\n",
        "\n",
        "\n",
        "# Normalize the features\n",
        "#scaler = StandardScaler()\n",
        "#features_scaled = scaler.fit_transform(features)\n",
        "#target_scaled= scaler.fit_transform(target.reshape(-1, 1))\n",
        "\n",
        "# Prepare the data for the model\n",
        "#X = features_scaled\n",
        "#y = target_scaled\n",
        "\n",
        "# Reshape the target variable to have the shape (number of samples, 168)\n",
        "#y_reshaped = np.array([y[i:i+168] for i in range(len(y) - 168)])\n",
        "\n",
        "# Adjust the input features accordingly\n",
        "#X = X[:-168]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y_reshaped, test_size=0.25, random_state=42)\n",
        "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "#if gpus:\n",
        " #   try:\n",
        "  #      for gpu in gpus:\n",
        "   #         tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    #except RuntimeError as e:\n",
        "     #   print(e)\n",
        "#dfx.dropna(inplace=True)\n",
        "#Drop dropout\n",
        "#http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43442.pdf\n",
        "def create_model(trial, input_dim):\n",
        "    inputs = Input(shape=(input_dim))#tf.keras.layers.Input(shape=input_dim)\n",
        "    norm = inputs#BatchNormalization()(inputs)\n",
        "    ll = norm\n",
        "    dropout = trial.suggest_categorical('dropout',[True, False])\n",
        "    if dropout:\n",
        "      rate = trial.suggest_float('dropout_rate', 0, 1)\n",
        "      drop = layers.Dropout(rate)(norm)\n",
        "      ll = drop\n",
        "\n",
        "    regularize_h1_activation = trial.suggest_categorical(\n",
        "            'regularize_h1_activation', [True, False])\n",
        "    regularize_h1_kernel = trial.suggest_categorical(\n",
        "            'regularize_h1_kernel', [True, False])\n",
        "    h1_activation_rate = (0.0 if not regularize_h1_activation\n",
        "                              else trial.suggest_float('h1_activation_rate_l1', 1e-5, 1e1, log=True))\n",
        "    h1_kernel_rate = (0.0 if not regularize_h1_kernel\n",
        "                          else trial.suggest_float('h1_kernel_rate_l1', 1e-5, 1e1, log=True))\n",
        "     # first hidden layer\n",
        "    hidden_layer1 = layers.Dense(trial.suggest_int('neurons_1', 16, 256, log=False),\n",
        "                                    activation=trial.suggest_categorical(\n",
        "                                        'activation_1',['elu','relu', 'tanh', 'softmax', 'sigmoid', 'softplus']),\n",
        "                                    kernel_regularizer=regularizers.L1(\n",
        "                                        h1_kernel_rate),\n",
        "                                    activity_regularizer=regularizers.L1(h1_activation_rate))(ll)\n",
        "\n",
        "    regularize_h2_activation = trial.suggest_categorical(\n",
        "            'regularize_h2_activation', [True, False])\n",
        "    regularize_h2_kernel = trial.suggest_categorical(\n",
        "            'regularize_h2_kernel', [True, False])\n",
        "    h2_activation_rate = (0.0 if not regularize_h2_activation\n",
        "                              else trial.suggest_float('h2_activation_rate_l1', 1e-5, 1e1, log=True))\n",
        "    h2_kernel_rate = (0.0 if not regularize_h2_kernel\n",
        "                          else trial.suggest_float('h2_kernel_rate_l1', 1e-5, 1e1, log=True))\n",
        "  # Second hidden layer\n",
        "    hidden_layer1 = LayerNormalization()(hidden_layer1)\n",
        "    hidden_layer2 = layers.Dense(trial.suggest_int('neurons_2', 16, 256, log=False),\n",
        "                                    activation=trial.suggest_categorical(\n",
        "                                        'activation_2',['elu','relu', 'tanh', 'softmax', 'sigmoid', 'softplus']),\n",
        "                                    kernel_regularizer=regularizers.L1(\n",
        "                                        h2_kernel_rate),\n",
        "                                    activity_regularizer=regularizers.L1(h2_activation_rate))(hidden_layer1)\n",
        "\n",
        "    # Output layer\n",
        "    hidden_layer2 = LayerNormalization()(hidden_layer1)\n",
        "    outputs = layers.Dense(192,activation='linear')(hidden_layer2)\n",
        "\n",
        "    # Define the model\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Learning rate for the optimizer#1e-5,\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-1, log=True)\n",
        "\n",
        "    # Compile the model\n",
        "    optimizer =  tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
        "\n",
        "    return model\n",
        "\n",
        "def objective(trial):\n",
        "    # Feature selection\n",
        "    features = train_val_set.drop(columns=['DateTime', 'Load_DA', 'Load_Act'])\n",
        "\n",
        "    selected_features = [feature for feature in features if trial.suggest_categorical(f'use_{feature}', [True, False])]\n",
        "\n",
        "    # Subset the features based on the selection\n",
        "    X_selected = features[selected_features].values\n",
        "    target = train_val_set['Load_DA'].values\n",
        "\n",
        "    # Normalize the selected features\n",
        "    scaler = RobustScaler()\n",
        "    X_selected_scaled = scaler.fit_transform(X_selected)\n",
        "    target_scaled = scaler.fit_transform(target.reshape(-1, 1))\n",
        "\n",
        "    # Reshape the target variable to have the shape (number of samples, 192)\n",
        "    y_reshaped = np.array([target_scaled[i:i+192] for i in range(0, len(target_scaled) - 192 + 1, 24)])\n",
        "\n",
        "    # Adjust the input features accordingly\n",
        "    X_selected_scaled = np.array([X_selected_scaled[i:i+192, :] for i in range(0, len(X_selected_scaled) - 192 + 1, 24)])\n",
        "\n",
        "    # Check the shapes\n",
        "\n",
        "    # Adjust the input features accordingly\n",
        "\n",
        "    #print(\"X_selected_scaled shape:\", X_selected_scaled.shape)\n",
        "    #print(\"y_reshaped shape:\", y_reshaped.shape)\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_selected_scaled, y_reshaped, test_size=0.25, random_state=42)\n",
        "\n",
        "    # Create the model\n",
        "    model = create_model(trial, input_dim=(X_train.shape[1], X_train.shape[2]))\n",
        "\n",
        "    # Train the model\n",
        "    callbacks = [tf.keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)]\n",
        "    model.fit(X_train, y_train, epochs=1000, callbacks=callbacks, batch_size=32, verbose=0, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "    return loss\n",
        "\n",
        "# Create a study object and optimize the objective function\n",
        "\n",
        "\n",
        "# Create a study object and optimize the objective function\n",
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=200)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print('Best hyperparameters:', study.best_params)\n",
        "best_params = study.best_params\n",
        "\n",
        "# Filter the parameters where the value is True\n",
        "true_params = {key: value for key, value in best_params.items() if value == True}\n",
        "\n",
        "# Now you can save `true_params` to a file, display it, or use it as needed\n",
        "print(true_params)\n",
        "\n",
        "# Optionally, save the filtered parameters to a file (e.g., a JSON file)\n",
        "import json\n",
        "\n",
        "with open('true_params1.json', 'w') as f:\n",
        "    json.dump(true_params, f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R7rIA3CbGAvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " best_params={'use_temp_actual': False, 'use_hour': True,\n",
        "              'use_day_of_week': True, 'use_month': True,\n",
        "              'use_load_lag_198': True, 'use_load_lag_336': True,\n",
        "              'use_load_lag_504': False, 'use_Rolling_Avg_15': False,\n",
        "              'use_Rolling_Std_15': True, 'use_Rolling_Sum_15': False,\n",
        "              'use_Rolling_Avg_30': False, 'use_Rolling_Sum_30': True,\n",
        "              'use_Rolling_Std_30': False, 'use_temp_lag_1': True,\n",
        "              'use_temp_lag_2': False, 'use_temp_lag_3': True,\n",
        "              'use_temp_mean_6': True, 'use_temp_mean_24': True,\n",
        "              'use_temp_lag_24': True, 'use_temp_lag_48': False,\n",
        "              'use_temp_min': False, 'use_temp_max': True,\n",
        "              'use_HDD': True, 'use_CDD': False,\n",
        "              'dropout': False, 'regularize_h1_activation': False,\n",
        "              'regularize_h1_kernel': False, 'neurons_1': 238,\n",
        "              'activation_1': 'tanh', 'regularize_h2_activation': True,\n",
        "              'regularize_h2_kernel': True, 'h2_activation_rate_l1': 0.002183364309811904,\n",
        "              'h2_kernel_rate_l1': 0.014619674726375919, 'neurons_2': 209, 'activation_2': 'elu',\n",
        "              'learning_rate': 0.008633292204680593}\n",
        "features = [['hour',\n",
        " 'day_of_week',\n",
        " 'month',\n",
        " 'load_lag_198',\n",
        " 'load_lag_336',\n",
        " 'Rolling_Std_15',\n",
        " 'Rolling_Sum_30',\n",
        " 'temp_lag_1',\n",
        " 'temp_lag_3',\n",
        " 'temp_mean_6',\n",
        " 'temp_mean_24',\n",
        " 'temp_lag_24',\n",
        " 'temp_max',\n",
        " 'HDD']]\n",
        " features\n",
        " train_val_set[['hour',\n",
        " 'day_of_week',\n",
        " 'month',\n",
        " 'load_lag_198',\n",
        " 'load_lag_336',\n",
        " 'Rolling_Std_15',\n",
        " 'Rolling_Sum_30',\n",
        " 'temp_lag_1',\n",
        " 'temp_lag_3',\n",
        " 'temp_mean_6',\n",
        " 'temp_mean_24',\n",
        " 'temp_lag_24',\n",
        " 'temp_max',\n",
        " 'HDD']]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "zGJHTabey2t8",
        "outputId": "160f870d-b676-4491-b5d4-c6566af558a6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       hour  day_of_week  month  load_lag_198  load_lag_336  Rolling_Std_15  \\\n",
              "8785      9            4      8       40800.0       50700.0     6506.236977   \n",
              "8786     10            4      8       39800.0       52250.0     6515.481029   \n",
              "8787     11            4      8       41000.0       53100.0     6525.775050   \n",
              "8788     12            4      8       43500.0       53800.0     6537.276579   \n",
              "8789     13            4      8       47300.0       54150.0     6546.028549   \n",
              "...     ...          ...    ...           ...           ...             ...   \n",
              "43820     4            1      8       40800.0       36050.0     5916.339521   \n",
              "43821     5            1      8       42850.0       36900.0     5908.784594   \n",
              "43822     6            1      8       39400.0       38950.0     5905.010186   \n",
              "43823     7            1      8       37000.0       42750.0     5905.366874   \n",
              "43824     8            1      8       35950.0       45950.0     5904.831068   \n",
              "\n",
              "       Rolling_Sum_30  temp_lag_1  temp_lag_3  temp_mean_6  temp_mean_24  \\\n",
              "8785       33981050.0       22.61       18.85    20.233333     22.138333   \n",
              "8786       33981400.0       24.64       20.73    21.668333     22.228333   \n",
              "8787       33981550.0       25.91       22.61    23.288333     22.326250   \n",
              "8788       33981750.0       26.99       24.64    24.741667     22.404583   \n",
              "8789       33981600.0       27.57       25.91    26.050000     22.494167   \n",
              "...               ...         ...         ...          ...           ...   \n",
              "43820      30662000.0       19.74       19.59    19.800000     22.163750   \n",
              "43821      30668250.0       19.40       19.67    19.601667     22.250417   \n",
              "43822      30676950.0       19.18       19.74    19.513333     22.302500   \n",
              "43823      30687000.0       19.50       19.40    19.623333     22.313333   \n",
              "43824      30697750.0       20.25       19.18    19.856667     22.302083   \n",
              "\n",
              "       temp_lag_24  temp_max  HDD  \n",
              "8785         22.24     26.93  0.0  \n",
              "8786         23.75     26.93  0.0  \n",
              "8787         24.64     26.99  0.0  \n",
              "8788         25.69     27.57  0.0  \n",
              "8789         26.43     28.58  0.0  \n",
              "...            ...       ...  ...  \n",
              "43820        17.17     26.34  0.0  \n",
              "43821        17.10     26.34  0.0  \n",
              "43822        18.25     26.34  0.0  \n",
              "43823        19.99     26.34  0.0  \n",
              "43824        21.34     26.34  0.0  \n",
              "\n",
              "[35040 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-daaf1779-7e81-4d3c-889d-690320094dda\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hour</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>month</th>\n",
              "      <th>load_lag_198</th>\n",
              "      <th>load_lag_336</th>\n",
              "      <th>Rolling_Std_15</th>\n",
              "      <th>Rolling_Sum_30</th>\n",
              "      <th>temp_lag_1</th>\n",
              "      <th>temp_lag_3</th>\n",
              "      <th>temp_mean_6</th>\n",
              "      <th>temp_mean_24</th>\n",
              "      <th>temp_lag_24</th>\n",
              "      <th>temp_max</th>\n",
              "      <th>HDD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8785</th>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>40800.0</td>\n",
              "      <td>50700.0</td>\n",
              "      <td>6506.236977</td>\n",
              "      <td>33981050.0</td>\n",
              "      <td>22.61</td>\n",
              "      <td>18.85</td>\n",
              "      <td>20.233333</td>\n",
              "      <td>22.138333</td>\n",
              "      <td>22.24</td>\n",
              "      <td>26.93</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8786</th>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>39800.0</td>\n",
              "      <td>52250.0</td>\n",
              "      <td>6515.481029</td>\n",
              "      <td>33981400.0</td>\n",
              "      <td>24.64</td>\n",
              "      <td>20.73</td>\n",
              "      <td>21.668333</td>\n",
              "      <td>22.228333</td>\n",
              "      <td>23.75</td>\n",
              "      <td>26.93</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8787</th>\n",
              "      <td>11</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>41000.0</td>\n",
              "      <td>53100.0</td>\n",
              "      <td>6525.775050</td>\n",
              "      <td>33981550.0</td>\n",
              "      <td>25.91</td>\n",
              "      <td>22.61</td>\n",
              "      <td>23.288333</td>\n",
              "      <td>22.326250</td>\n",
              "      <td>24.64</td>\n",
              "      <td>26.99</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8788</th>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>43500.0</td>\n",
              "      <td>53800.0</td>\n",
              "      <td>6537.276579</td>\n",
              "      <td>33981750.0</td>\n",
              "      <td>26.99</td>\n",
              "      <td>24.64</td>\n",
              "      <td>24.741667</td>\n",
              "      <td>22.404583</td>\n",
              "      <td>25.69</td>\n",
              "      <td>27.57</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8789</th>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>47300.0</td>\n",
              "      <td>54150.0</td>\n",
              "      <td>6546.028549</td>\n",
              "      <td>33981600.0</td>\n",
              "      <td>27.57</td>\n",
              "      <td>25.91</td>\n",
              "      <td>26.050000</td>\n",
              "      <td>22.494167</td>\n",
              "      <td>26.43</td>\n",
              "      <td>28.58</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43820</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>40800.0</td>\n",
              "      <td>36050.0</td>\n",
              "      <td>5916.339521</td>\n",
              "      <td>30662000.0</td>\n",
              "      <td>19.74</td>\n",
              "      <td>19.59</td>\n",
              "      <td>19.800000</td>\n",
              "      <td>22.163750</td>\n",
              "      <td>17.17</td>\n",
              "      <td>26.34</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43821</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>42850.0</td>\n",
              "      <td>36900.0</td>\n",
              "      <td>5908.784594</td>\n",
              "      <td>30668250.0</td>\n",
              "      <td>19.40</td>\n",
              "      <td>19.67</td>\n",
              "      <td>19.601667</td>\n",
              "      <td>22.250417</td>\n",
              "      <td>17.10</td>\n",
              "      <td>26.34</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43822</th>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>39400.0</td>\n",
              "      <td>38950.0</td>\n",
              "      <td>5905.010186</td>\n",
              "      <td>30676950.0</td>\n",
              "      <td>19.18</td>\n",
              "      <td>19.74</td>\n",
              "      <td>19.513333</td>\n",
              "      <td>22.302500</td>\n",
              "      <td>18.25</td>\n",
              "      <td>26.34</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43823</th>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>37000.0</td>\n",
              "      <td>42750.0</td>\n",
              "      <td>5905.366874</td>\n",
              "      <td>30687000.0</td>\n",
              "      <td>19.50</td>\n",
              "      <td>19.40</td>\n",
              "      <td>19.623333</td>\n",
              "      <td>22.313333</td>\n",
              "      <td>19.99</td>\n",
              "      <td>26.34</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43824</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>35950.0</td>\n",
              "      <td>45950.0</td>\n",
              "      <td>5904.831068</td>\n",
              "      <td>30697750.0</td>\n",
              "      <td>20.25</td>\n",
              "      <td>19.18</td>\n",
              "      <td>19.856667</td>\n",
              "      <td>22.302083</td>\n",
              "      <td>21.34</td>\n",
              "      <td>26.34</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>35040 rows × 14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-daaf1779-7e81-4d3c-889d-690320094dda')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-daaf1779-7e81-4d3c-889d-690320094dda button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-daaf1779-7e81-4d3c-889d-690320094dda');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e574afdf-8bf1-40c0-960c-2da3104e887e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e574afdf-8bf1-40c0-960c-2da3104e887e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e574afdf-8bf1-40c0-960c-2da3104e887e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"'HDD']]\",\n  \"rows\": 35040,\n  \"fields\": [\n    {\n      \"column\": \"hour\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          17,\n          1,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day_of_week\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          4,\n          5,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          6,\n          5,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"load_lag_198\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11319.864679885006,\n        \"min\": 28650.0,\n        \"max\": 87850.0,\n        \"num_unique_values\": 1223,\n        \"samples\": [\n          72750.0,\n          38800.0,\n          49450.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"load_lag_336\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11315.048989080235,\n        \"min\": 28650.0,\n        \"max\": 87850.0,\n        \"num_unique_values\": 1223,\n        \"samples\": [\n          72900.0,\n          49000.0,\n          37200.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rolling_Std_15\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1035.2773293555929,\n        \"min\": 4078.2316015621695,\n        \"max\": 11449.837496938138,\n        \"num_unique_values\": 34902,\n        \"samples\": [\n          5820.477304377441,\n          5403.980915026299,\n          5461.1549069623625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rolling_Sum_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6579174.492491071,\n        \"min\": 29016650.0,\n        \"max\": 51744050.0,\n        \"num_unique_values\": 32826,\n        \"samples\": [\n          41436650.0,\n          29451300.0,\n          31969372.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temp_lag_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.092654386064368,\n        \"min\": -2.63,\n        \"max\": 36.06,\n        \"num_unique_values\": 3558,\n        \"samples\": [\n          20.5111111111111,\n          27.02,\n          29.66\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temp_lag_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.092653479603318,\n        \"min\": -2.63,\n        \"max\": 36.06,\n        \"num_unique_values\": 3558,\n        \"samples\": [\n          20.5111111111111,\n          25.72,\n          29.66\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temp_mean_6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.969683228342063,\n        \"min\": -1.9733333333333334,\n        \"max\": 35.528333333333336,\n        \"num_unique_values\": 18550,\n        \"samples\": [\n          14.043333333333331,\n          8.413333333333332,\n          18.861666666666668\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temp_mean_24\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.477245912194679,\n        \"min\": -0.15374999999999997,\n        \"max\": 29.265833333333333,\n        \"num_unique_values\": 28384,\n        \"samples\": [\n          14.420416666666666,\n          19.39,\n          22.241249999999997\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temp_lag_24\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.092656159615009,\n        \"min\": -2.63,\n        \"max\": 36.06,\n        \"num_unique_values\": 3558,\n        \"samples\": [\n          20.5111111111111,\n          26.67,\n          29.66\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temp_max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.226408313691938,\n        \"min\": 2.69,\n        \"max\": 36.06,\n        \"num_unique_values\": 2271,\n        \"samples\": [\n          20.37,\n          4.68,\n          8.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"HDD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.166818670728652,\n        \"min\": 0.0,\n        \"max\": 20.63,\n        \"num_unique_values\": 1972,\n        \"samples\": [\n          13.85,\n          14.1,\n          19.55\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import StandardScaler,MinMaxScaler,RobustScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error,mean_absolute_percentage_error\n",
        "\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Dropout,BatchNormalization,LayerNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers, Model, Input,regularizers\n",
        "import statistics\n",
        "\n",
        "os.listdir('/content/')\n",
        "file_path = '/content/pythondf.csv'\n",
        "dfload = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#def median_absolute_error(y_true, y_pred):\n",
        " #   error= tfp.stats.percentile(abs(y_true-y_pred), q=50.)\n",
        "  #  return error\n",
        "\n",
        "\n",
        "\n",
        "dfload = dfload.drop(dfload.columns[0], axis=1)\n",
        "# Define a function to add '00:00:00' if time component is missing\n",
        "def add_missing_time_component(date_str):\n",
        "    if len(date_str) == 10:  # Assuming 'YYYY-MM-DD' format\n",
        "        return date_str + ' 00:00:00'\n",
        "    return date_str\n",
        "\n",
        "# Apply the function to the DateTime column\n",
        "dfload['DateTime'] = dfload['DateTime'].apply(add_missing_time_component)\n",
        "\n",
        "# Now convert the DateTime column to datetime format\n",
        "dfload['DateTime'] = pd.to_datetime(dfload['DateTime'], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
        "\n",
        "\n",
        "# Convert the datetime column to datetime objects\n",
        "dfload['DateTime'] = pd.to_datetime(dfload['DateTime'])\n",
        "\n",
        "# Extract hour of the day, day of the week, and month of the year\n",
        "dfload['hour'] = dfload['DateTime'].dt.hour\n",
        "dfload['day_of_week'] = dfload['DateTime'].dt.dayofweek  # Monday=0, Sunday=6\n",
        "dfload['month'] = dfload['DateTime'].dt.month\n",
        "\n",
        "# Convert these variables to dummy variables\n",
        "#df_hour_dummies = pd.get_dummies(dfload['hour'], prefix='hour').astype(int)\n",
        "#df_day_dummies = pd.get_dummies(dfload['day_of_week'], prefix='day_of_week').astype(int)\n",
        "#df_month_dummies = pd.get_dummies(dfload['month'], prefix='month').astype(int)\n",
        "\n",
        "\n",
        "\n",
        "# Generate lagged features for temperature\n",
        "for lag in [198,336,504]:\n",
        "    dfload[f'load_lag_{lag}'] = dfload['Load_DA'].shift(lag)\n",
        "\n",
        "dfload[\"Rolling_Avg_15\"] = dfload[\"Load_DA\"].rolling(window=15*24).mean().shift(7*24)\n",
        "dfload[\"Rolling_Std_15\"] = dfload[\"Load_DA\"].rolling(window=15*24).std().shift(7*24)\n",
        "dfload[\"Rolling_Sum_15\"] = dfload[\"Load_DA\"].rolling(window=15*24).sum().shift(7*24)\n",
        "dfload[\"Rolling_Avg_30\"] = dfload[\"Load_DA\"].rolling(window=30*24).mean().shift(7*24)\n",
        "dfload[\"Rolling_Sum_30\"] = dfload[\"Load_DA\"].rolling(window=30*24).sum().shift(7*24)\n",
        "# Calculate the moving standard deviation over the last 30 days, excluding the first 7 days\n",
        "dfload[\"Rolling_Std_30\"] = dfload[\"Load_DA\"].rolling(window=30*24).std().shift(7*24)\n",
        "\n",
        "for lag in range(1, 4):\n",
        "    dfload[f'temp_lag_{lag}'] = dfload['temp_actual'].shift(lag)\n",
        "\n",
        "# Generate rolling mean features for temperature\n",
        "for window in [6,24]:\n",
        "    dfload[f'temp_mean_{window}'] = dfload['temp_actual'].rolling(window=window).mean()\n",
        "\n",
        "# Generate min and max features for temperature over the last 24 hours\n",
        " ##temp_min_24 =  dfload['temp_actual'].rolling(window=24).min()\n",
        "\n",
        " #dfload['temp_max_24'] =  dfload['temp_actual'].rolling(window=24).max()\n",
        "\n",
        "# Generate lag features for temperature at 24, 48, and 96 hours\n",
        "for lag in [24, 48]:\n",
        "     dfload[f'temp_lag_{lag}'] =  dfload['temp_actual'].shift(lag)\n",
        "\n",
        "# Generate lag features for wind speed\n",
        "#for lag in range(1, 8):\n",
        " #    dfload[f'wspd_lag_{lag}'] =  dfload['wspd_actual'].shift(lag)\n",
        "\n",
        "#for lag in range(1, 8):\n",
        " #   dfload[f'dwpt_lag_{lag}'] = dfload['dwpt_actual'].shift(lag)\n",
        "\n",
        "#for lag in range(1, 8):\n",
        "  #dfload[f'pres_lag_{lag}'] = dfload['pres_actual'].shift(lag)\n",
        "\n",
        "#for window in [2,4,8,12,24]:\n",
        " #   dfload[f'dew_mean_{window}'] = dfload['dwpt_actual'].rolling(window=window).mean()\n",
        "# Generate min and max features for temperature over the last 24 hours\n",
        "dfload['temp_min'] =  dfload['temp_actual'].rolling(window=24).min()\n",
        "dfload['temp_max'] =  dfload['temp_actual'].rolling(window=24).max()\n",
        "\n",
        "\n",
        "# Assuming df is your DataFrame with relevant columns\n",
        "\n",
        "# Wind Chill calculation\n",
        "#def calculate_wind_chill(temp, wind_speed):\n",
        " #   # Only calculate wind chill if temperature < 10°C and wind speed > 4.8 km/h\n",
        "  #  wind_chill = np.where(\n",
        "   #     (temp < 10) & (wind_speed > 4.8),\n",
        "    #    13.12 + 0.6215 * temp - 11.37 * (wind_speed ** 0.16) + 0.3965 * temp * (wind_speed ** 0.16),\n",
        "     #   temp\n",
        "    #)\n",
        "    #return wind_chill\n",
        "\n",
        "# Humidity calculation\n",
        "#def calculate_humidity(temp, dew_point):\n",
        " #   humidity = 100 * (np.exp((17.625 * dew_point) / (dew_point + 243.04)) /\n",
        "  #                    np.exp((17.625 * temp) / (temp + 243.04)))\n",
        "   # return humidity\n",
        "\n",
        "# Apply the calculations to the DataFrame\n",
        "#dfload['Wind_Chill'] = calculate_wind_chill(dfload['temp_actual'], dfload['wspd_actual'])\n",
        "#dfload['Humidity'] = calculate_humidity(dfload['temp_actual'], dfload['dwpt_actual'])\n",
        "\n",
        "\n",
        "#for lag in range(1, 6):\n",
        "   # dfload[f'Wind_Chill_L{lag}'] = dfload['Wind_Chill'].shift(lag)\n",
        " #   dfload[f'Humidity_L{lag}'] = dfload['Humidity'].shift(lag)\n",
        "\n",
        "#for window in [4,8,12,24]:\n",
        "    #dfload[f'Wind_Chill_M{window}'] = dfload['Wind_Chill'].rolling(window=window).mean()\n",
        "   # dfload[f'Humidity_M{window}'] = dfload['Humidity'].rolling(window=window).mean()\n",
        "\n",
        "#Example: \"Climate Change and Energy Demand in France\" by Hallegatte et al., which discusses the impact of temperature on energy demand and uses 18°C as a reference for HDD.\n",
        "T_base = 18\n",
        "\n",
        "# Calculate HDD and CDD\n",
        "dfload['HDD'] = dfload['temp_actual'].apply(lambda x: max(0, T_base - x))\n",
        "\n",
        "dfload['CDD'] = dfload['temp_actual'].apply(lambda x: max(0, x - T_base))\n",
        "#for lag in range(1, 8):\n",
        "    #dfload[f'HDD_L{lag}'] = dfload['HDD'].shift(lag)\n",
        "   # dfload[f'CDD_L{lag}'] = dfload['CDD'].shift(lag)\n",
        "#for window in [4,6,8,12,24]:\n",
        " #   dfload[f'HDD_M{window}'] = dfload['HDD'].rolling(window=window).mean()\n",
        "  #  dfload[f'CDD_M{window}'] = dfload['CDD'].rolling(window=window).mean()\n",
        "\n",
        "#dfload['dwpt_min'] =  dfload['dwpt_actual'].rolling(window=24).min()\n",
        "#dfload['dwpt_max'] =  dfload['dwpt_actual'].rolling(window=24).max()\n",
        "#dfload['pres_min'] =  dfload['pres_actual'].rolling(window=24).min()\n",
        "#dfload['pres_max'] =  dfload['pres_actual'].rolling(window=24).max()\n",
        "#fload['wspd_min'] =  dfload['wspd_actual'].rolling(window=24).min()\n",
        "#dfload['wspd_max'] =  dfload['wspd_actual'].rolling(window=24).max()\n",
        "#dfload['HDD_min'] =  dfload['HDD'].rolling(window=24).min()\n",
        "#dfload['HDD_max'] =  dfload['HDD'].rolling(window=24).max()\n",
        "#dfload['CDD_min'] =  dfload['CDD'].rolling(window=24).min()\n",
        "#dfload['CDD_max'] =  dfload['CDD'].rolling(window=24).max()\n",
        "#dfload['Wind_Chill_min'] =  dfload['Wind_Chill'].rolling(window=24).min()\n",
        "#dfload['Wind_Chill_max'] =  dfload['Wind_Chill'].rolling(window=24).max()\n",
        "#dfload['Humidity_min'] =  dfload['Humidity'].rolling(window=24).min()\n",
        "#dfload['Humidity_max'] =  dfload['Humidity'].rolling(window=24).max()\n",
        "\n",
        "# Combine original DataFrame with dummy variables\n",
        "#f_combined = pd.concat([dfload, df_hour_dummies, df_day_dummies, df_month_dummies], axis=1)\n",
        "#f_combined = pd.concat([dfload, df_day_dummies, df_month_dummies], axis=1)\n",
        "#dfload['hourdm'] =pd.get_dummies(dfload['hour'], prefix='hour').astype(int)\n",
        "#f_combined = pd.concat([dfload, df_day_dummies, df_month_dummies], axis=1)\n",
        "dfx = pd.concat([dfload.drop(columns=['dwpt_actual','wspd_actual','pres_actual'])], axis=1)\n",
        "#dfx = pd.concat([f_combined.drop(columns=['month','day_of_week','wspd_actual'])], axis=1)\n",
        "\n",
        "window = slice(8785, 43825)\n",
        "train_val_set = dfx[window]\n",
        "\n",
        "test_set = dfx[43825:]\n",
        "#features = train_val_set[features]#.drop(columns=['DateTime',\t'Load_DA',\t'Load_Act'])\n",
        "#target = train_val_set['Load_DA'].values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Subset the features based on the selection\n",
        "X_selected = train_val_set[['hour',\n",
        " 'day_of_week',\n",
        " 'month',\n",
        " 'load_lag_198',\n",
        " 'load_lag_336',\n",
        " 'Rolling_Std_15',\n",
        " 'Rolling_Sum_30',\n",
        " 'temp_lag_1',\n",
        " 'temp_lag_3',\n",
        " 'temp_mean_6',\n",
        " 'temp_mean_24',\n",
        " 'temp_lag_24',\n",
        " 'temp_max',\n",
        " 'HDD']]\n",
        "target = train_val_set['Load_DA'].values\n",
        "\n",
        "    # Normalize the selected features\n",
        "scaler = RobustScaler()\n",
        "X_selected_scaled = scaler.fit_transform(X_selected)\n",
        "target_scaled = scaler.fit_transform(target.reshape(-1, 1))\n",
        "\n",
        "    # Reshape the target variable to have the shape (number of samples, 192)\n",
        "y_reshaped = np.array([target_scaled[i:i+192] for i in range(0, len(target_scaled) - 192 + 1, 24)])\n",
        "\n",
        "    # Adjust the input features accordingly\n",
        "X_selected_scaled = np.array([X_selected_scaled[i:i+192, :] for i in range(0, len(X_selected_scaled) - 192 + 1, 24)])\n",
        "\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected_scaled, y_reshaped, test_size=0.25, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
        "ll = inputs\n",
        "\n",
        "\n",
        "\n",
        "hidden_layer1 = layers.Dense(best_params['neurons_1'],\n",
        "                                    activation=best_params['activation_1'])(ll)\n",
        "\n",
        "\n",
        "hidden_layer1 = LayerNormalization()(hidden_layer1)\n",
        "hidden_layer2 = layers.Dense(best_params['neurons_2'],\n",
        "                                    activation=best_params['activation_2'],\n",
        "                                    kernel_regularizer=regularizers.L1(\n",
        "                                        best_params['regularize_h2_kernel']),\n",
        "                                    activity_regularizer=regularizers.L1(best_params['regularize_h2_activation']))(hidden_layer1)\n",
        "\n",
        "    # Output layer\n",
        "hidden_layer2 = LayerNormalization()(hidden_layer1)\n",
        "outputs = layers.Dense(192,activation='linear')(hidden_layer2)\n",
        "\n",
        "    # Define the model\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "    # Compile the model\n",
        "optimizer =  tf.keras.optimizers.Adam(learning_rate=best_params['learning_rate'])\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='mean_absolute_error')\n",
        "    # Train the mode\n",
        "callbacks = [tf.keras.callbacks.EarlyStopping(patience=50, restore_best_weights=True)]\n",
        "model.fit(X_train, y_train, epochs=1000, callbacks=callbacks, batch_size=32, verbose=1, validation_data=(X_test, y_test))\n",
        "\n",
        "    # Evaluate the model\n",
        "\n",
        "\n",
        "    # Learning rate for the optimizer#1e-5,\n",
        "\n",
        "\n",
        "\n",
        "    # Evaluate the model\n",
        "loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wikG7dSzNM-",
        "outputId": "e1532ec0-872b-4d4b-d943-07a1920a068d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - loss: 0.4635 - val_loss: 0.3403\n",
            "Epoch 2/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - loss: 0.3428 - val_loss: 0.2035\n",
            "Epoch 3/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 0.2123 - val_loss: 0.1932\n",
            "Epoch 4/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 146ms/step - loss: 0.1976 - val_loss: 0.2224\n",
            "Epoch 5/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - loss: 0.2217 - val_loss: 0.2014\n",
            "Epoch 6/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 145ms/step - loss: 0.2257 - val_loss: 0.1907\n",
            "Epoch 7/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.1839 - val_loss: 0.2542\n",
            "Epoch 8/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - loss: 0.2550 - val_loss: 0.2026\n",
            "Epoch 9/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - loss: 0.1879 - val_loss: 0.1813\n",
            "Epoch 10/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.1852 - val_loss: 0.1631\n",
            "Epoch 11/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 126ms/step - loss: 0.1723 - val_loss: 0.1842\n",
            "Epoch 12/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 140ms/step - loss: 0.1911 - val_loss: 0.1599\n",
            "Epoch 13/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.1669 - val_loss: 0.1567\n",
            "Epoch 14/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - loss: 0.1655 - val_loss: 0.1525\n",
            "Epoch 15/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - loss: 0.1680 - val_loss: 0.1952\n",
            "Epoch 16/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - loss: 0.2038 - val_loss: 0.1524\n",
            "Epoch 17/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 154ms/step - loss: 0.1641 - val_loss: 0.1712\n",
            "Epoch 18/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - loss: 0.1651 - val_loss: 0.1552\n",
            "Epoch 19/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - loss: 0.1560 - val_loss: 0.1589\n",
            "Epoch 20/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - loss: 0.1606 - val_loss: 0.1406\n",
            "Epoch 21/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.1564 - val_loss: 0.1578\n",
            "Epoch 22/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - loss: 0.1650 - val_loss: 0.1435\n",
            "Epoch 23/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.1520 - val_loss: 0.1519\n",
            "Epoch 24/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - loss: 0.1573 - val_loss: 0.1566\n",
            "Epoch 25/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.1595 - val_loss: 0.1336\n",
            "Epoch 26/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - loss: 0.1448 - val_loss: 0.1340\n",
            "Epoch 27/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 160ms/step - loss: 0.1448 - val_loss: 0.1330\n",
            "Epoch 28/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.1423 - val_loss: 0.1753\n",
            "Epoch 29/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.1782 - val_loss: 0.1583\n",
            "Epoch 30/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - loss: 0.1486 - val_loss: 0.1308\n",
            "Epoch 31/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - loss: 0.1401 - val_loss: 0.1409\n",
            "Epoch 32/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.1556 - val_loss: 0.1437\n",
            "Epoch 33/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - loss: 0.1642 - val_loss: 0.1325\n",
            "Epoch 34/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - loss: 0.1392 - val_loss: 0.1301\n",
            "Epoch 35/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - loss: 0.1386 - val_loss: 0.1558\n",
            "Epoch 36/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.1528 - val_loss: 0.1345\n",
            "Epoch 37/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.1607 - val_loss: 0.1303\n",
            "Epoch 38/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 157ms/step - loss: 0.1434 - val_loss: 0.1279\n",
            "Epoch 39/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 108ms/step - loss: 0.1426 - val_loss: 0.1310\n",
            "Epoch 40/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 122ms/step - loss: 0.1464 - val_loss: 0.1305\n",
            "Epoch 41/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 142ms/step - loss: 0.1438 - val_loss: 0.1286\n",
            "Epoch 42/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - loss: 0.1348 - val_loss: 0.1336\n",
            "Epoch 43/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - loss: 0.1392 - val_loss: 0.1344\n",
            "Epoch 44/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - loss: 0.1506 - val_loss: 0.1297\n",
            "Epoch 45/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.1437 - val_loss: 0.1271\n",
            "Epoch 46/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - loss: 0.1373 - val_loss: 0.1250\n",
            "Epoch 47/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - loss: 0.1323 - val_loss: 0.1306\n",
            "Epoch 48/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.1342 - val_loss: 0.1382\n",
            "Epoch 49/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.1459 - val_loss: 0.1252\n",
            "Epoch 50/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - loss: 0.1359 - val_loss: 0.1325\n",
            "Epoch 51/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 136ms/step - loss: 0.1411 - val_loss: 0.1306\n",
            "Epoch 52/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - loss: 0.1341 - val_loss: 0.1266\n",
            "Epoch 53/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - loss: 0.1321 - val_loss: 0.1486\n",
            "Epoch 54/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - loss: 0.1432 - val_loss: 0.1260\n",
            "Epoch 55/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - loss: 0.1352 - val_loss: 0.1303\n",
            "Epoch 56/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.1371 - val_loss: 0.1293\n",
            "Epoch 57/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 144ms/step - loss: 0.1386 - val_loss: 0.1272\n",
            "Epoch 58/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.1351 - val_loss: 0.1247\n",
            "Epoch 59/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - loss: 0.1271 - val_loss: 0.1472\n",
            "Epoch 60/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - loss: 0.1335 - val_loss: 0.1275\n",
            "Epoch 61/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.1347 - val_loss: 0.1219\n",
            "Epoch 62/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - loss: 0.1285 - val_loss: 0.1222\n",
            "Epoch 63/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - loss: 0.1331 - val_loss: 0.1280\n",
            "Epoch 64/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - loss: 0.1324 - val_loss: 0.1301\n",
            "Epoch 65/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 158ms/step - loss: 0.1396 - val_loss: 0.1221\n",
            "Epoch 66/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - loss: 0.1287 - val_loss: 0.1218\n",
            "Epoch 67/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - loss: 0.1352 - val_loss: 0.1210\n",
            "Epoch 68/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.1276 - val_loss: 0.1233\n",
            "Epoch 69/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - loss: 0.1265 - val_loss: 0.1235\n",
            "Epoch 70/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - loss: 0.1248 - val_loss: 0.1379\n",
            "Epoch 71/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.1449 - val_loss: 0.1320\n",
            "Epoch 72/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - loss: 0.1304 - val_loss: 0.1428\n",
            "Epoch 73/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.1390 - val_loss: 0.1287\n",
            "Epoch 74/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.1296 - val_loss: 0.1192\n",
            "Epoch 75/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - loss: 0.1276 - val_loss: 0.1253\n",
            "Epoch 76/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.1381 - val_loss: 0.1236\n",
            "Epoch 77/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - loss: 0.1333 - val_loss: 0.1223\n",
            "Epoch 78/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - loss: 0.1343 - val_loss: 0.1259\n",
            "Epoch 79/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.1314 - val_loss: 0.1485\n",
            "Epoch 80/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - loss: 0.1616 - val_loss: 0.1239\n",
            "Epoch 81/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - loss: 0.1424 - val_loss: 0.1451\n",
            "Epoch 82/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - loss: 0.1658 - val_loss: 0.1275\n",
            "Epoch 83/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - loss: 0.1295 - val_loss: 0.1256\n",
            "Epoch 84/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.1302 - val_loss: 0.1257\n",
            "Epoch 85/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - loss: 0.1295 - val_loss: 0.1195\n",
            "Epoch 86/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - loss: 0.1273 - val_loss: 0.1294\n",
            "Epoch 87/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 122ms/step - loss: 0.1323 - val_loss: 0.1221\n",
            "Epoch 88/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - loss: 0.1243 - val_loss: 0.1274\n",
            "Epoch 89/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.1331 - val_loss: 0.1205\n",
            "Epoch 90/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - loss: 0.1252 - val_loss: 0.1188\n",
            "Epoch 91/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - loss: 0.1277 - val_loss: 0.1186\n",
            "Epoch 92/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - loss: 0.1268 - val_loss: 0.1316\n",
            "Epoch 93/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - loss: 0.1446 - val_loss: 0.1221\n",
            "Epoch 94/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - loss: 0.1239 - val_loss: 0.1330\n",
            "Epoch 95/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.1361 - val_loss: 0.1214\n",
            "Epoch 96/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - loss: 0.1332 - val_loss: 0.1292\n",
            "Epoch 97/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - loss: 0.1426 - val_loss: 0.1218\n",
            "Epoch 98/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.1284 - val_loss: 0.1185\n",
            "Epoch 99/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 144ms/step - loss: 0.1268 - val_loss: 0.1175\n",
            "Epoch 100/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - loss: 0.1209 - val_loss: 0.1172\n",
            "Epoch 101/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 0.1343 - val_loss: 0.1208\n",
            "Epoch 102/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - loss: 0.1257 - val_loss: 0.1281\n",
            "Epoch 103/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.1356 - val_loss: 0.1337\n",
            "Epoch 104/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - loss: 0.1393 - val_loss: 0.1164\n",
            "Epoch 105/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - loss: 0.1246 - val_loss: 0.1266\n",
            "Epoch 106/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - loss: 0.1371 - val_loss: 0.1257\n",
            "Epoch 107/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - loss: 0.1249 - val_loss: 0.1371\n",
            "Epoch 108/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.1455 - val_loss: 0.1497\n",
            "Epoch 109/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.1473 - val_loss: 0.1150\n",
            "Epoch 110/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - loss: 0.1269 - val_loss: 0.1176\n",
            "Epoch 111/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.1230 - val_loss: 0.1187\n",
            "Epoch 112/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 111ms/step - loss: 0.1260 - val_loss: 0.1379\n",
            "Epoch 113/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - loss: 0.1514 - val_loss: 0.1412\n",
            "Epoch 114/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - loss: 0.1364 - val_loss: 0.1164\n",
            "Epoch 115/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - loss: 0.1230 - val_loss: 0.1278\n",
            "Epoch 116/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - loss: 0.1423 - val_loss: 0.1142\n",
            "Epoch 117/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - loss: 0.1191 - val_loss: 0.1193\n",
            "Epoch 118/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - loss: 0.1239 - val_loss: 0.1232\n",
            "Epoch 119/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.1356 - val_loss: 0.1194\n",
            "Epoch 120/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - loss: 0.1198 - val_loss: 0.1130\n",
            "Epoch 121/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - loss: 0.1195 - val_loss: 0.1303\n",
            "Epoch 122/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.1427 - val_loss: 0.1211\n",
            "Epoch 123/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.1188 - val_loss: 0.1168\n",
            "Epoch 124/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - loss: 0.1169 - val_loss: 0.1140\n",
            "Epoch 125/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.1219 - val_loss: 0.1216\n",
            "Epoch 126/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - loss: 0.1207 - val_loss: 0.1235\n",
            "Epoch 127/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.1355 - val_loss: 0.1264\n",
            "Epoch 128/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - loss: 0.1225 - val_loss: 0.1146\n",
            "Epoch 129/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 145ms/step - loss: 0.1181 - val_loss: 0.1136\n",
            "Epoch 130/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - loss: 0.1181 - val_loss: 0.1172\n",
            "Epoch 131/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.1214 - val_loss: 0.1337\n",
            "Epoch 132/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 155ms/step - loss: 0.1462 - val_loss: 0.1158\n",
            "Epoch 133/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - loss: 0.1210 - val_loss: 0.1177\n",
            "Epoch 134/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.1236 - val_loss: 0.1202\n",
            "Epoch 135/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 154ms/step - loss: 0.1207 - val_loss: 0.1185\n",
            "Epoch 136/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - loss: 0.1252 - val_loss: 0.1128\n",
            "Epoch 137/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - loss: 0.1145 - val_loss: 0.1183\n",
            "Epoch 138/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - loss: 0.1254 - val_loss: 0.1202\n",
            "Epoch 139/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - loss: 0.1268 - val_loss: 0.1135\n",
            "Epoch 140/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - loss: 0.1208 - val_loss: 0.1100\n",
            "Epoch 141/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - loss: 0.1148 - val_loss: 0.1378\n",
            "Epoch 142/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 156ms/step - loss: 0.1272 - val_loss: 0.1327\n",
            "Epoch 143/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.1265 - val_loss: 0.1466\n",
            "Epoch 144/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.1297 - val_loss: 0.1112\n",
            "Epoch 145/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - loss: 0.1188 - val_loss: 0.1120\n",
            "Epoch 146/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - loss: 0.1177 - val_loss: 0.1131\n",
            "Epoch 147/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 0.1158 - val_loss: 0.1155\n",
            "Epoch 148/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - loss: 0.1161 - val_loss: 0.1088\n",
            "Epoch 149/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.1141 - val_loss: 0.1120\n",
            "Epoch 150/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.1139 - val_loss: 0.1108\n",
            "Epoch 151/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - loss: 0.1195 - val_loss: 0.1373\n",
            "Epoch 152/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 111ms/step - loss: 0.1266 - val_loss: 0.1171\n",
            "Epoch 153/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - loss: 0.1177 - val_loss: 0.1242\n",
            "Epoch 154/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.1190 - val_loss: 0.1139\n",
            "Epoch 155/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.1131 - val_loss: 0.1223\n",
            "Epoch 156/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - loss: 0.1205 - val_loss: 0.1384\n",
            "Epoch 157/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 124ms/step - loss: 0.1332 - val_loss: 0.1101\n",
            "Epoch 158/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - loss: 0.1199 - val_loss: 0.1122\n",
            "Epoch 159/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.1180 - val_loss: 0.1131\n",
            "Epoch 160/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - loss: 0.1230 - val_loss: 0.1150\n",
            "Epoch 161/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - loss: 0.1167 - val_loss: 0.1113\n",
            "Epoch 162/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.1277 - val_loss: 0.1202\n",
            "Epoch 163/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - loss: 0.1161 - val_loss: 0.1116\n",
            "Epoch 164/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - loss: 0.1150 - val_loss: 0.1065\n",
            "Epoch 165/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - loss: 0.1099 - val_loss: 0.1289\n",
            "Epoch 166/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - loss: 0.1339 - val_loss: 0.1111\n",
            "Epoch 167/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 130ms/step - loss: 0.1213 - val_loss: 0.1125\n",
            "Epoch 168/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.1127 - val_loss: 0.1095\n",
            "Epoch 169/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - loss: 0.1122 - val_loss: 0.1102\n",
            "Epoch 170/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.1144 - val_loss: 0.1058\n",
            "Epoch 171/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - loss: 0.1110 - val_loss: 0.1342\n",
            "Epoch 172/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - loss: 0.1348 - val_loss: 0.1096\n",
            "Epoch 173/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.1176 - val_loss: 0.1128\n",
            "Epoch 174/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 112ms/step - loss: 0.1153 - val_loss: 0.1378\n",
            "Epoch 175/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 153ms/step - loss: 0.1420 - val_loss: 0.1120\n",
            "Epoch 176/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 129ms/step - loss: 0.1141 - val_loss: 0.1054\n",
            "Epoch 177/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - loss: 0.1087 - val_loss: 0.1123\n",
            "Epoch 178/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.1127 - val_loss: 0.1105\n",
            "Epoch 179/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 154ms/step - loss: 0.1148 - val_loss: 0.1071\n",
            "Epoch 180/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - loss: 0.1077 - val_loss: 0.1188\n",
            "Epoch 181/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - loss: 0.1131 - val_loss: 0.1064\n",
            "Epoch 182/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - loss: 0.1145 - val_loss: 0.1350\n",
            "Epoch 183/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - loss: 0.1266 - val_loss: 0.1162\n",
            "Epoch 184/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - loss: 0.1123 - val_loss: 0.1158\n",
            "Epoch 185/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 156ms/step - loss: 0.1177 - val_loss: 0.1094\n",
            "Epoch 186/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.1140 - val_loss: 0.1073\n",
            "Epoch 187/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.1094 - val_loss: 0.1047\n",
            "Epoch 188/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 145ms/step - loss: 0.1078 - val_loss: 0.1054\n",
            "Epoch 189/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 130ms/step - loss: 0.1089 - val_loss: 0.1287\n",
            "Epoch 190/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 142ms/step - loss: 0.1284 - val_loss: 0.1052\n",
            "Epoch 191/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.1112 - val_loss: 0.1026\n",
            "Epoch 192/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - loss: 0.1068 - val_loss: 0.1031\n",
            "Epoch 193/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - loss: 0.1065 - val_loss: 0.1025\n",
            "Epoch 194/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.1059 - val_loss: 0.1087\n",
            "Epoch 195/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 141ms/step - loss: 0.1099 - val_loss: 0.1143\n",
            "Epoch 196/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - loss: 0.1120 - val_loss: 0.1113\n",
            "Epoch 197/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.1142 - val_loss: 0.1059\n",
            "Epoch 198/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 152ms/step - loss: 0.1160 - val_loss: 0.1060\n",
            "Epoch 199/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - loss: 0.1090 - val_loss: 0.1031\n",
            "Epoch 200/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 161ms/step - loss: 0.1100 - val_loss: 0.1339\n",
            "Epoch 201/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - loss: 0.1334 - val_loss: 0.1467\n",
            "Epoch 202/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.1264 - val_loss: 0.1218\n",
            "Epoch 203/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 121ms/step - loss: 0.1156 - val_loss: 0.1096\n",
            "Epoch 204/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - loss: 0.1145 - val_loss: 0.1010\n",
            "Epoch 205/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 130ms/step - loss: 0.1075 - val_loss: 0.1077\n",
            "Epoch 206/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - loss: 0.1195 - val_loss: 0.1060\n",
            "Epoch 207/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 125ms/step - loss: 0.1091 - val_loss: 0.1035\n",
            "Epoch 208/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - loss: 0.1050 - val_loss: 0.1002\n",
            "Epoch 209/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 125ms/step - loss: 0.1045 - val_loss: 0.1083\n",
            "Epoch 210/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - loss: 0.1040 - val_loss: 0.0997\n",
            "Epoch 211/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.1038 - val_loss: 0.1035\n",
            "Epoch 212/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - loss: 0.1041 - val_loss: 0.1322\n",
            "Epoch 213/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - loss: 0.1270 - val_loss: 0.1103\n",
            "Epoch 214/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 110ms/step - loss: 0.1063 - val_loss: 0.1020\n",
            "Epoch 215/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.1061 - val_loss: 0.1014\n",
            "Epoch 216/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - loss: 0.1094 - val_loss: 0.1166\n",
            "Epoch 217/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 122ms/step - loss: 0.1106 - val_loss: 0.1449\n",
            "Epoch 218/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 147ms/step - loss: 0.1295 - val_loss: 0.1015\n",
            "Epoch 219/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - loss: 0.1049 - val_loss: 0.1276\n",
            "Epoch 220/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - loss: 0.1258 - val_loss: 0.1291\n",
            "Epoch 221/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - loss: 0.1202 - val_loss: 0.1031\n",
            "Epoch 222/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 153ms/step - loss: 0.1035 - val_loss: 0.1118\n",
            "Epoch 223/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 120ms/step - loss: 0.1184 - val_loss: 0.0979\n",
            "Epoch 224/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - loss: 0.1014 - val_loss: 0.1024\n",
            "Epoch 225/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 124ms/step - loss: 0.1026 - val_loss: 0.0980\n",
            "Epoch 226/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - loss: 0.1009 - val_loss: 0.1061\n",
            "Epoch 227/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 126ms/step - loss: 0.1077 - val_loss: 0.1007\n",
            "Epoch 228/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 141ms/step - loss: 0.1129 - val_loss: 0.0986\n",
            "Epoch 229/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.1040 - val_loss: 0.1002\n",
            "Epoch 230/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 126ms/step - loss: 0.1029 - val_loss: 0.1009\n",
            "Epoch 231/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - loss: 0.1011 - val_loss: 0.1044\n",
            "Epoch 232/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.1124 - val_loss: 0.1069\n",
            "Epoch 233/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - loss: 0.1016 - val_loss: 0.1005\n",
            "Epoch 234/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 130ms/step - loss: 0.0993 - val_loss: 0.0979\n",
            "Epoch 235/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.1001 - val_loss: 0.0950\n",
            "Epoch 236/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - loss: 0.1013 - val_loss: 0.0996\n",
            "Epoch 237/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - loss: 0.1060 - val_loss: 0.1025\n",
            "Epoch 238/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.1017 - val_loss: 0.1142\n",
            "Epoch 239/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.1193 - val_loss: 0.1016\n",
            "Epoch 240/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.1037 - val_loss: 0.1063\n",
            "Epoch 241/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 114ms/step - loss: 0.1141 - val_loss: 0.0964\n",
            "Epoch 242/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 163ms/step - loss: 0.1011 - val_loss: 0.0995\n",
            "Epoch 243/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - loss: 0.1024 - val_loss: 0.1070\n",
            "Epoch 244/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 163ms/step - loss: 0.1102 - val_loss: 0.0980\n",
            "Epoch 245/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.1014 - val_loss: 0.0996\n",
            "Epoch 246/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.1058 - val_loss: 0.0994\n",
            "Epoch 247/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - loss: 0.1054 - val_loss: 0.1132\n",
            "Epoch 248/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.1227 - val_loss: 0.1071\n",
            "Epoch 249/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - loss: 0.1119 - val_loss: 0.1088\n",
            "Epoch 250/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 130ms/step - loss: 0.1115 - val_loss: 0.0984\n",
            "Epoch 251/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.1049 - val_loss: 0.1008\n",
            "Epoch 252/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - loss: 0.1090 - val_loss: 0.1013\n",
            "Epoch 253/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - loss: 0.1059 - val_loss: 0.1004\n",
            "Epoch 254/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - loss: 0.1003 - val_loss: 0.0956\n",
            "Epoch 255/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - loss: 0.0986 - val_loss: 0.0958\n",
            "Epoch 256/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.0973 - val_loss: 0.0969\n",
            "Epoch 257/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - loss: 0.1026 - val_loss: 0.1126\n",
            "Epoch 258/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 159ms/step - loss: 0.1197 - val_loss: 0.0947\n",
            "Epoch 259/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.0982 - val_loss: 0.0937\n",
            "Epoch 260/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - loss: 0.1041 - val_loss: 0.1037\n",
            "Epoch 261/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - loss: 0.1036 - val_loss: 0.1086\n",
            "Epoch 262/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0990 - val_loss: 0.0927\n",
            "Epoch 263/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0996 - val_loss: 0.1040\n",
            "Epoch 264/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - loss: 0.1048 - val_loss: 0.0935\n",
            "Epoch 265/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0932 - val_loss: 0.1131\n",
            "Epoch 266/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - loss: 0.1062 - val_loss: 0.0932\n",
            "Epoch 267/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - loss: 0.0977 - val_loss: 0.0944\n",
            "Epoch 268/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0974 - val_loss: 0.0990\n",
            "Epoch 269/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.1063 - val_loss: 0.0931\n",
            "Epoch 270/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - loss: 0.0963 - val_loss: 0.1017\n",
            "Epoch 271/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.1014 - val_loss: 0.0918\n",
            "Epoch 272/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.0950 - val_loss: 0.1009\n",
            "Epoch 273/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 144ms/step - loss: 0.1108 - val_loss: 0.0980\n",
            "Epoch 274/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.1011 - val_loss: 0.0940\n",
            "Epoch 275/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.1039 - val_loss: 0.1544\n",
            "Epoch 276/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - loss: 0.1322 - val_loss: 0.1519\n",
            "Epoch 277/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.1146 - val_loss: 0.1140\n",
            "Epoch 278/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - loss: 0.1084 - val_loss: 0.0947\n",
            "Epoch 279/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - loss: 0.0976 - val_loss: 0.0950\n",
            "Epoch 280/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0994 - val_loss: 0.0958\n",
            "Epoch 281/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 154ms/step - loss: 0.0996 - val_loss: 0.0987\n",
            "Epoch 282/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 113ms/step - loss: 0.1029 - val_loss: 0.1009\n",
            "Epoch 283/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - loss: 0.1014 - val_loss: 0.0911\n",
            "Epoch 284/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0964 - val_loss: 0.0968\n",
            "Epoch 285/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.1031 - val_loss: 0.1144\n",
            "Epoch 286/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - loss: 0.1125 - val_loss: 0.0960\n",
            "Epoch 287/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.0966 - val_loss: 0.0941\n",
            "Epoch 288/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.0955 - val_loss: 0.0966\n",
            "Epoch 289/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - loss: 0.0982 - val_loss: 0.0937\n",
            "Epoch 290/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0938 - val_loss: 0.1202\n",
            "Epoch 291/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.1043 - val_loss: 0.1054\n",
            "Epoch 292/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 154ms/step - loss: 0.1026 - val_loss: 0.1035\n",
            "Epoch 293/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 111ms/step - loss: 0.1031 - val_loss: 0.1009\n",
            "Epoch 294/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - loss: 0.1129 - val_loss: 0.0976\n",
            "Epoch 295/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - loss: 0.1114 - val_loss: 0.0916\n",
            "Epoch 296/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.0936 - val_loss: 0.0896\n",
            "Epoch 297/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0924 - val_loss: 0.0922\n",
            "Epoch 298/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 132ms/step - loss: 0.0956 - val_loss: 0.1007\n",
            "Epoch 299/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - loss: 0.0944 - val_loss: 0.0893\n",
            "Epoch 300/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 146ms/step - loss: 0.0966 - val_loss: 0.1354\n",
            "Epoch 301/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 114ms/step - loss: 0.1183 - val_loss: 0.0918\n",
            "Epoch 302/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - loss: 0.0932 - val_loss: 0.0909\n",
            "Epoch 303/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - loss: 0.0916 - val_loss: 0.1166\n",
            "Epoch 304/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.1126 - val_loss: 0.1387\n",
            "Epoch 305/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.1082 - val_loss: 0.1138\n",
            "Epoch 306/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.1208 - val_loss: 0.0999\n",
            "Epoch 307/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 154ms/step - loss: 0.0947 - val_loss: 0.0895\n",
            "Epoch 308/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - loss: 0.0932 - val_loss: 0.0993\n",
            "Epoch 309/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - loss: 0.0991 - val_loss: 0.0920\n",
            "Epoch 310/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - loss: 0.0921 - val_loss: 0.0937\n",
            "Epoch 311/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0943 - val_loss: 0.1166\n",
            "Epoch 312/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - loss: 0.1017 - val_loss: 0.0886\n",
            "Epoch 313/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - loss: 0.0920 - val_loss: 0.0953\n",
            "Epoch 314/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0997 - val_loss: 0.0969\n",
            "Epoch 315/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - loss: 0.0950 - val_loss: 0.0972\n",
            "Epoch 316/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0963 - val_loss: 0.1213\n",
            "Epoch 317/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.1059 - val_loss: 0.0938\n",
            "Epoch 318/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0925 - val_loss: 0.0998\n",
            "Epoch 319/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - loss: 0.0938 - val_loss: 0.0929\n",
            "Epoch 320/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 157ms/step - loss: 0.0946 - val_loss: 0.0957\n",
            "Epoch 321/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0947 - val_loss: 0.1141\n",
            "Epoch 322/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - loss: 0.1076 - val_loss: 0.0895\n",
            "Epoch 323/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - loss: 0.0905 - val_loss: 0.1031\n",
            "Epoch 324/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - loss: 0.1017 - val_loss: 0.0939\n",
            "Epoch 325/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - loss: 0.0954 - val_loss: 0.0969\n",
            "Epoch 326/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 156ms/step - loss: 0.0996 - val_loss: 0.0940\n",
            "Epoch 327/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - loss: 0.0909 - val_loss: 0.0882\n",
            "Epoch 328/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - loss: 0.0885 - val_loss: 0.1148\n",
            "Epoch 329/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 142ms/step - loss: 0.1096 - val_loss: 0.0926\n",
            "Epoch 330/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0917 - val_loss: 0.0871\n",
            "Epoch 331/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - loss: 0.0911 - val_loss: 0.0893\n",
            "Epoch 332/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - loss: 0.0931 - val_loss: 0.1120\n",
            "Epoch 333/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0985 - val_loss: 0.0873\n",
            "Epoch 334/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - loss: 0.0903 - val_loss: 0.0961\n",
            "Epoch 335/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - loss: 0.1034 - val_loss: 0.0946\n",
            "Epoch 336/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.0926 - val_loss: 0.1027\n",
            "Epoch 337/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 157ms/step - loss: 0.1043 - val_loss: 0.0903\n",
            "Epoch 338/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - loss: 0.0939 - val_loss: 0.0862\n",
            "Epoch 339/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - loss: 0.0916 - val_loss: 0.0907\n",
            "Epoch 340/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 209ms/step - loss: 0.0914 - val_loss: 0.0859\n",
            "Epoch 341/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - loss: 0.0897 - val_loss: 0.1000\n",
            "Epoch 342/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - loss: 0.1056 - val_loss: 0.0925\n",
            "Epoch 343/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - loss: 0.0897 - val_loss: 0.0899\n",
            "Epoch 344/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0949 - val_loss: 0.0973\n",
            "Epoch 345/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 156ms/step - loss: 0.0941 - val_loss: 0.0866\n",
            "Epoch 346/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 153ms/step - loss: 0.0868 - val_loss: 0.0854\n",
            "Epoch 347/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 154ms/step - loss: 0.0892 - val_loss: 0.0914\n",
            "Epoch 348/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 133ms/step - loss: 0.0965 - val_loss: 0.0887\n",
            "Epoch 349/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 141ms/step - loss: 0.0957 - val_loss: 0.0895\n",
            "Epoch 350/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.0901 - val_loss: 0.1455\n",
            "Epoch 351/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.1483 - val_loss: 0.0906\n",
            "Epoch 352/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - loss: 0.0980 - val_loss: 0.0996\n",
            "Epoch 353/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.1104 - val_loss: 0.1026\n",
            "Epoch 354/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - loss: 0.0941 - val_loss: 0.1105\n",
            "Epoch 355/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - loss: 0.1046 - val_loss: 0.0897\n",
            "Epoch 356/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.0939 - val_loss: 0.0914\n",
            "Epoch 357/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 151ms/step - loss: 0.0911 - val_loss: 0.0871\n",
            "Epoch 358/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0912 - val_loss: 0.0856\n",
            "Epoch 359/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0848 - val_loss: 0.1067\n",
            "Epoch 360/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 156ms/step - loss: 0.1003 - val_loss: 0.0881\n",
            "Epoch 361/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0963 - val_loss: 0.0992\n",
            "Epoch 362/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - loss: 0.0946 - val_loss: 0.0859\n",
            "Epoch 363/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - loss: 0.0905 - val_loss: 0.1013\n",
            "Epoch 364/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 127ms/step - loss: 0.0971 - val_loss: 0.0875\n",
            "Epoch 365/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - loss: 0.0872 - val_loss: 0.1124\n",
            "Epoch 366/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.1134 - val_loss: 0.1233\n",
            "Epoch 367/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.1233 - val_loss: 0.0870\n",
            "Epoch 368/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 156ms/step - loss: 0.0881 - val_loss: 0.0891\n",
            "Epoch 369/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - loss: 0.0902 - val_loss: 0.0981\n",
            "Epoch 370/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 159ms/step - loss: 0.1000 - val_loss: 0.0850\n",
            "Epoch 371/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 124ms/step - loss: 0.0889 - val_loss: 0.0885\n",
            "Epoch 372/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - loss: 0.0910 - val_loss: 0.0910\n",
            "Epoch 373/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0874 - val_loss: 0.0864\n",
            "Epoch 374/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - loss: 0.0888 - val_loss: 0.1056\n",
            "Epoch 375/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - loss: 0.1008 - val_loss: 0.0948\n",
            "Epoch 376/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0939 - val_loss: 0.1000\n",
            "Epoch 377/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 154ms/step - loss: 0.0898 - val_loss: 0.1012\n",
            "Epoch 378/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 125ms/step - loss: 0.0972 - val_loss: 0.0912\n",
            "Epoch 379/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - loss: 0.0942 - val_loss: 0.0884\n",
            "Epoch 380/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - loss: 0.0920 - val_loss: 0.0904\n",
            "Epoch 381/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0946 - val_loss: 0.0860\n",
            "Epoch 382/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - loss: 0.0891 - val_loss: 0.0866\n",
            "Epoch 383/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0860 - val_loss: 0.0855\n",
            "Epoch 384/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - loss: 0.0859 - val_loss: 0.0848\n",
            "Epoch 385/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 146ms/step - loss: 0.0862 - val_loss: 0.0927\n",
            "Epoch 386/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 135ms/step - loss: 0.0967 - val_loss: 0.0961\n",
            "Epoch 387/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - loss: 0.0936 - val_loss: 0.0877\n",
            "Epoch 388/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0931 - val_loss: 0.0941\n",
            "Epoch 389/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - loss: 0.1040 - val_loss: 0.0890\n",
            "Epoch 390/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - loss: 0.0907 - val_loss: 0.0950\n",
            "Epoch 391/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0897 - val_loss: 0.0886\n",
            "Epoch 392/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - loss: 0.0864 - val_loss: 0.0827\n",
            "Epoch 393/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - loss: 0.0876 - val_loss: 0.0973\n",
            "Epoch 394/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - loss: 0.0964 - val_loss: 0.0842\n",
            "Epoch 395/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - loss: 0.0877 - val_loss: 0.0875\n",
            "Epoch 396/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - loss: 0.0957 - val_loss: 0.0915\n",
            "Epoch 397/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 127ms/step - loss: 0.0885 - val_loss: 0.0875\n",
            "Epoch 398/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 164ms/step - loss: 0.0917 - val_loss: 0.0823\n",
            "Epoch 399/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0878 - val_loss: 0.0863\n",
            "Epoch 400/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0889 - val_loss: 0.0995\n",
            "Epoch 401/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 156ms/step - loss: 0.1079 - val_loss: 0.0913\n",
            "Epoch 402/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.0917 - val_loss: 0.1120\n",
            "Epoch 403/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 133ms/step - loss: 0.1079 - val_loss: 0.1056\n",
            "Epoch 404/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - loss: 0.1115 - val_loss: 0.0996\n",
            "Epoch 405/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0904 - val_loss: 0.0893\n",
            "Epoch 406/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - loss: 0.0877 - val_loss: 0.0924\n",
            "Epoch 407/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - loss: 0.0892 - val_loss: 0.0825\n",
            "Epoch 408/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0871 - val_loss: 0.0860\n",
            "Epoch 409/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - loss: 0.0888 - val_loss: 0.0869\n",
            "Epoch 410/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - loss: 0.0881 - val_loss: 0.0824\n",
            "Epoch 411/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0840 - val_loss: 0.0930\n",
            "Epoch 412/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - loss: 0.0859 - val_loss: 0.0881\n",
            "Epoch 413/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - loss: 0.0904 - val_loss: 0.1039\n",
            "Epoch 414/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - loss: 0.0989 - val_loss: 0.1063\n",
            "Epoch 415/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - loss: 0.0918 - val_loss: 0.0906\n",
            "Epoch 416/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - loss: 0.0911 - val_loss: 0.0878\n",
            "Epoch 417/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0922 - val_loss: 0.1071\n",
            "Epoch 418/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - loss: 0.0964 - val_loss: 0.0873\n",
            "Epoch 419/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - loss: 0.0858 - val_loss: 0.0891\n",
            "Epoch 420/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - loss: 0.0929 - val_loss: 0.0908\n",
            "Epoch 421/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0889 - val_loss: 0.1040\n",
            "Epoch 422/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - loss: 0.1014 - val_loss: 0.1296\n",
            "Epoch 423/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.1052 - val_loss: 0.1037\n",
            "Epoch 424/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - loss: 0.0938 - val_loss: 0.0830\n",
            "Epoch 425/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0863 - val_loss: 0.0841\n",
            "Epoch 426/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0827 - val_loss: 0.0847\n",
            "Epoch 427/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 151ms/step - loss: 0.0892 - val_loss: 0.1004\n",
            "Epoch 428/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 125ms/step - loss: 0.0945 - val_loss: 0.1104\n",
            "Epoch 429/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - loss: 0.1015 - val_loss: 0.0867\n",
            "Epoch 430/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0880 - val_loss: 0.0911\n",
            "Epoch 431/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - loss: 0.0856 - val_loss: 0.0804\n",
            "Epoch 432/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - loss: 0.0844 - val_loss: 0.0880\n",
            "Epoch 433/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0882 - val_loss: 0.0837\n",
            "Epoch 434/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - loss: 0.0829 - val_loss: 0.0936\n",
            "Epoch 435/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - loss: 0.0900 - val_loss: 0.0880\n",
            "Epoch 436/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - loss: 0.0867 - val_loss: 0.0890\n",
            "Epoch 437/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0874 - val_loss: 0.0875\n",
            "Epoch 438/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0872 - val_loss: 0.0798\n",
            "Epoch 439/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 158ms/step - loss: 0.0843 - val_loss: 0.0959\n",
            "Epoch 440/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0904 - val_loss: 0.1133\n",
            "Epoch 441/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.1020 - val_loss: 0.0889\n",
            "Epoch 442/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 166ms/step - loss: 0.0896 - val_loss: 0.0853\n",
            "Epoch 443/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 123ms/step - loss: 0.0887 - val_loss: 0.0834\n",
            "Epoch 444/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 146ms/step - loss: 0.0844 - val_loss: 0.0860\n",
            "Epoch 445/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.1058 - val_loss: 0.1006\n",
            "Epoch 446/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - loss: 0.0881 - val_loss: 0.1337\n",
            "Epoch 447/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 145ms/step - loss: 0.1125 - val_loss: 0.1082\n",
            "Epoch 448/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.1000 - val_loss: 0.0894\n",
            "Epoch 449/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - loss: 0.0861 - val_loss: 0.0923\n",
            "Epoch 450/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - loss: 0.0876 - val_loss: 0.0785\n",
            "Epoch 451/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0824 - val_loss: 0.0788\n",
            "Epoch 452/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.0817 - val_loss: 0.0828\n",
            "Epoch 453/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - loss: 0.0831 - val_loss: 0.0825\n",
            "Epoch 454/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - loss: 0.0912 - val_loss: 0.0817\n",
            "Epoch 455/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 143ms/step - loss: 0.0796 - val_loss: 0.0820\n",
            "Epoch 456/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - loss: 0.0915 - val_loss: 0.0951\n",
            "Epoch 457/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - loss: 0.0985 - val_loss: 0.0983\n",
            "Epoch 458/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 126ms/step - loss: 0.0943 - val_loss: 0.0915\n",
            "Epoch 459/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 169ms/step - loss: 0.0879 - val_loss: 0.0850\n",
            "Epoch 460/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 121ms/step - loss: 0.0879 - val_loss: 0.0847\n",
            "Epoch 461/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - loss: 0.0839 - val_loss: 0.1040\n",
            "Epoch 462/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 128ms/step - loss: 0.1028 - val_loss: 0.0791\n",
            "Epoch 463/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - loss: 0.0790 - val_loss: 0.0806\n",
            "Epoch 464/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0790 - val_loss: 0.0878\n",
            "Epoch 465/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - loss: 0.0849 - val_loss: 0.0821\n",
            "Epoch 466/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - loss: 0.0818 - val_loss: 0.0842\n",
            "Epoch 467/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0852 - val_loss: 0.0951\n",
            "Epoch 468/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - loss: 0.0915 - val_loss: 0.0856\n",
            "Epoch 469/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - loss: 0.0850 - val_loss: 0.0826\n",
            "Epoch 470/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0801 - val_loss: 0.0776\n",
            "Epoch 471/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0800 - val_loss: 0.0780\n",
            "Epoch 472/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - loss: 0.0803 - val_loss: 0.0986\n",
            "Epoch 473/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.0918 - val_loss: 0.0800\n",
            "Epoch 474/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0856 - val_loss: 0.0846\n",
            "Epoch 475/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0811 - val_loss: 0.0771\n",
            "Epoch 476/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0790 - val_loss: 0.0871\n",
            "Epoch 477/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 159ms/step - loss: 0.0831 - val_loss: 0.0948\n",
            "Epoch 478/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - loss: 0.1054 - val_loss: 0.0854\n",
            "Epoch 479/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0848 - val_loss: 0.0807\n",
            "Epoch 480/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - loss: 0.0820 - val_loss: 0.0767\n",
            "Epoch 481/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - loss: 0.0829 - val_loss: 0.0892\n",
            "Epoch 482/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0856 - val_loss: 0.0839\n",
            "Epoch 483/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.0822 - val_loss: 0.0788\n",
            "Epoch 484/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0805 - val_loss: 0.0824\n",
            "Epoch 485/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 156ms/step - loss: 0.0828 - val_loss: 0.0776\n",
            "Epoch 486/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - loss: 0.0807 - val_loss: 0.0926\n",
            "Epoch 487/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 218ms/step - loss: 0.0901 - val_loss: 0.0950\n",
            "Epoch 488/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - loss: 0.0878 - val_loss: 0.0784\n",
            "Epoch 489/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - loss: 0.0805 - val_loss: 0.0791\n",
            "Epoch 490/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - loss: 0.0850 - val_loss: 0.0895\n",
            "Epoch 491/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - loss: 0.0874 - val_loss: 0.0827\n",
            "Epoch 492/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 169ms/step - loss: 0.0836 - val_loss: 0.0768\n",
            "Epoch 493/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - loss: 0.0803 - val_loss: 0.0852\n",
            "Epoch 494/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 127ms/step - loss: 0.0850 - val_loss: 0.1138\n",
            "Epoch 495/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - loss: 0.0925 - val_loss: 0.0768\n",
            "Epoch 496/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.0774 - val_loss: 0.0776\n",
            "Epoch 497/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - loss: 0.0832 - val_loss: 0.0802\n",
            "Epoch 498/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0807 - val_loss: 0.0774\n",
            "Epoch 499/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - loss: 0.0777 - val_loss: 0.0876\n",
            "Epoch 500/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - loss: 0.0865 - val_loss: 0.0908\n",
            "Epoch 501/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 148ms/step - loss: 0.0852 - val_loss: 0.0785\n",
            "Epoch 502/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 157ms/step - loss: 0.0801 - val_loss: 0.0777\n",
            "Epoch 503/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.0826 - val_loss: 0.1280\n",
            "Epoch 504/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.1123 - val_loss: 0.0831\n",
            "Epoch 505/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - loss: 0.0796 - val_loss: 0.0781\n",
            "Epoch 506/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 164ms/step - loss: 0.0791 - val_loss: 0.0777\n",
            "Epoch 507/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 225ms/step - loss: 0.0782 - val_loss: 0.0831\n",
            "Epoch 508/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 119ms/step - loss: 0.0848 - val_loss: 0.0904\n",
            "Epoch 509/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 154ms/step - loss: 0.0831 - val_loss: 0.0766\n",
            "Epoch 510/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 132ms/step - loss: 0.0797 - val_loss: 0.0755\n",
            "Epoch 511/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 152ms/step - loss: 0.0785 - val_loss: 0.0746\n",
            "Epoch 512/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 123ms/step - loss: 0.0793 - val_loss: 0.0891\n",
            "Epoch 513/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - loss: 0.0884 - val_loss: 0.0770\n",
            "Epoch 514/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 126ms/step - loss: 0.0857 - val_loss: 0.0855\n",
            "Epoch 515/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - loss: 0.0874 - val_loss: 0.0834\n",
            "Epoch 516/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 140ms/step - loss: 0.0849 - val_loss: 0.0791\n",
            "Epoch 517/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.0762 - val_loss: 0.0818\n",
            "Epoch 518/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - loss: 0.0820 - val_loss: 0.0763\n",
            "Epoch 519/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0780 - val_loss: 0.0810\n",
            "Epoch 520/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 112ms/step - loss: 0.0825 - val_loss: 0.0880\n",
            "Epoch 521/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0826 - val_loss: 0.0854\n",
            "Epoch 522/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 170ms/step - loss: 0.0837 - val_loss: 0.0753\n",
            "Epoch 523/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 245ms/step - loss: 0.0769 - val_loss: 0.0909\n",
            "Epoch 524/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 162ms/step - loss: 0.0859 - val_loss: 0.0902\n",
            "Epoch 525/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 130ms/step - loss: 0.0928 - val_loss: 0.0782\n",
            "Epoch 526/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0817 - val_loss: 0.0784\n",
            "Epoch 527/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - loss: 0.0788 - val_loss: 0.0998\n",
            "Epoch 528/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - loss: 0.0931 - val_loss: 0.0828\n",
            "Epoch 529/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 126ms/step - loss: 0.0784 - val_loss: 0.1110\n",
            "Epoch 530/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0957 - val_loss: 0.0770\n",
            "Epoch 531/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 187ms/step - loss: 0.0765 - val_loss: 0.0975\n",
            "Epoch 532/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 119ms/step - loss: 0.0855 - val_loss: 0.0779\n",
            "Epoch 533/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 159ms/step - loss: 0.0775 - val_loss: 0.0791\n",
            "Epoch 534/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - loss: 0.0795 - val_loss: 0.0768\n",
            "Epoch 535/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - loss: 0.0776 - val_loss: 0.0828\n",
            "Epoch 536/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 256ms/step - loss: 0.0794 - val_loss: 0.0770\n",
            "Epoch 537/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.0759 - val_loss: 0.0875\n",
            "Epoch 538/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - loss: 0.0794 - val_loss: 0.0818\n",
            "Epoch 539/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0810 - val_loss: 0.0933\n",
            "Epoch 540/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0943 - val_loss: 0.1161\n",
            "Epoch 541/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 179ms/step - loss: 0.0922 - val_loss: 0.0767\n",
            "Epoch 542/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0771 - val_loss: 0.1127\n",
            "Epoch 543/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - loss: 0.0925 - val_loss: 0.0798\n",
            "Epoch 544/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - loss: 0.0805 - val_loss: 0.0906\n",
            "Epoch 545/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0845 - val_loss: 0.0908\n",
            "Epoch 546/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - loss: 0.0869 - val_loss: 0.0791\n",
            "Epoch 547/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - loss: 0.0856 - val_loss: 0.1049\n",
            "Epoch 548/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0991 - val_loss: 0.0985\n",
            "Epoch 549/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - loss: 0.0840 - val_loss: 0.0788\n",
            "Epoch 550/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0771 - val_loss: 0.0759\n",
            "Epoch 551/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0779 - val_loss: 0.0808\n",
            "Epoch 552/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - loss: 0.0754 - val_loss: 0.0827\n",
            "Epoch 553/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 0.0790 - val_loss: 0.0812\n",
            "Epoch 554/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - loss: 0.0750 - val_loss: 0.0817\n",
            "Epoch 555/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 162ms/step - loss: 0.0830 - val_loss: 0.0750\n",
            "Epoch 556/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 133ms/step - loss: 0.0786 - val_loss: 0.1097\n",
            "Epoch 557/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 158ms/step - loss: 0.0901 - val_loss: 0.0732\n",
            "Epoch 558/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - loss: 0.0734 - val_loss: 0.0822\n",
            "Epoch 559/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - loss: 0.0830 - val_loss: 0.0906\n",
            "Epoch 560/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.0852 - val_loss: 0.0839\n",
            "Epoch 561/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 179ms/step - loss: 0.0779 - val_loss: 0.0825\n",
            "Epoch 562/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 116ms/step - loss: 0.0768 - val_loss: 0.0736\n",
            "Epoch 563/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 156ms/step - loss: 0.0784 - val_loss: 0.0783\n",
            "Epoch 564/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - loss: 0.0773 - val_loss: 0.0961\n",
            "Epoch 565/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 115ms/step - loss: 0.0920 - val_loss: 0.0922\n",
            "Epoch 566/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0864 - val_loss: 0.0777\n",
            "Epoch 567/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - loss: 0.0757 - val_loss: 0.0753\n",
            "Epoch 568/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - loss: 0.0761 - val_loss: 0.0768\n",
            "Epoch 569/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 114ms/step - loss: 0.0834 - val_loss: 0.0754\n",
            "Epoch 570/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - loss: 0.0758 - val_loss: 0.1070\n",
            "Epoch 571/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - loss: 0.1047 - val_loss: 0.0838\n",
            "Epoch 572/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 172ms/step - loss: 0.0787 - val_loss: 0.0849\n",
            "Epoch 573/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0873 - val_loss: 0.0756\n",
            "Epoch 574/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - loss: 0.0760 - val_loss: 0.0761\n",
            "Epoch 575/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - loss: 0.0732 - val_loss: 0.0768\n",
            "Epoch 576/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0807 - val_loss: 0.0770\n",
            "Epoch 577/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - loss: 0.0768 - val_loss: 0.0750\n",
            "Epoch 578/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 134ms/step - loss: 0.0780 - val_loss: 0.0787\n",
            "Epoch 579/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0789 - val_loss: 0.0897\n",
            "Epoch 580/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - loss: 0.0826 - val_loss: 0.0758\n",
            "Epoch 581/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0767 - val_loss: 0.0744\n",
            "Epoch 582/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0739 - val_loss: 0.0809\n",
            "Epoch 583/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - loss: 0.0828 - val_loss: 0.0763\n",
            "Epoch 584/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0745 - val_loss: 0.0966\n",
            "Epoch 585/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - loss: 0.0937 - val_loss: 0.0756\n",
            "Epoch 586/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 160ms/step - loss: 0.0764 - val_loss: 0.0770\n",
            "Epoch 587/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 123ms/step - loss: 0.0766 - val_loss: 0.0810\n",
            "Epoch 588/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 166ms/step - loss: 0.0816 - val_loss: 0.1007\n",
            "Epoch 589/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 124ms/step - loss: 0.0934 - val_loss: 0.0848\n",
            "Epoch 590/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 171ms/step - loss: 0.0828 - val_loss: 0.1346\n",
            "Epoch 591/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - loss: 0.1020 - val_loss: 0.1203\n",
            "Epoch 592/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - loss: 0.0951 - val_loss: 0.0748\n",
            "Epoch 593/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - loss: 0.0785 - val_loss: 0.0834\n",
            "Epoch 594/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0782 - val_loss: 0.0807\n",
            "Epoch 595/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - loss: 0.0762 - val_loss: 0.0720\n",
            "Epoch 596/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - loss: 0.0722 - val_loss: 0.0908\n",
            "Epoch 597/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 139ms/step - loss: 0.0823 - val_loss: 0.0761\n",
            "Epoch 598/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - loss: 0.0748 - val_loss: 0.0923\n",
            "Epoch 599/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.0895 - val_loss: 0.1058\n",
            "Epoch 600/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 157ms/step - loss: 0.0960 - val_loss: 0.0812\n",
            "Epoch 601/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - loss: 0.0771 - val_loss: 0.0903\n",
            "Epoch 602/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 160ms/step - loss: 0.0936 - val_loss: 0.0837\n",
            "Epoch 603/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0782 - val_loss: 0.0741\n",
            "Epoch 604/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0729 - val_loss: 0.0724\n",
            "Epoch 605/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - loss: 0.0741 - val_loss: 0.0732\n",
            "Epoch 606/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 121ms/step - loss: 0.0722 - val_loss: 0.0760\n",
            "Epoch 607/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 161ms/step - loss: 0.0745 - val_loss: 0.0898\n",
            "Epoch 608/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - loss: 0.0846 - val_loss: 0.0728\n",
            "Epoch 609/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - loss: 0.0768 - val_loss: 0.0978\n",
            "Epoch 610/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - loss: 0.0889 - val_loss: 0.0768\n",
            "Epoch 611/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 134ms/step - loss: 0.0753 - val_loss: 0.0773\n",
            "Epoch 612/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - loss: 0.0932 - val_loss: 0.0771\n",
            "Epoch 613/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - loss: 0.0769 - val_loss: 0.0876\n",
            "Epoch 614/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 140ms/step - loss: 0.0857 - val_loss: 0.0725\n",
            "Epoch 615/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - loss: 0.0747 - val_loss: 0.1096\n",
            "Epoch 616/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - loss: 0.0921 - val_loss: 0.0763\n",
            "Epoch 617/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 169ms/step - loss: 0.0750 - val_loss: 0.0744\n",
            "Epoch 618/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.0724 - val_loss: 0.0750\n",
            "Epoch 619/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - loss: 0.0786 - val_loss: 0.0788\n",
            "Epoch 620/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 162ms/step - loss: 0.0752 - val_loss: 0.0762\n",
            "Epoch 621/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 131ms/step - loss: 0.0754 - val_loss: 0.0879\n",
            "Epoch 622/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 169ms/step - loss: 0.0787 - val_loss: 0.0859\n",
            "Epoch 623/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 129ms/step - loss: 0.0792 - val_loss: 0.0747\n",
            "Epoch 624/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 175ms/step - loss: 0.0740 - val_loss: 0.0736\n",
            "Epoch 625/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - loss: 0.0742 - val_loss: 0.0734\n",
            "Epoch 626/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 182ms/step - loss: 0.0740 - val_loss: 0.1015\n",
            "Epoch 627/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 134ms/step - loss: 0.0948 - val_loss: 0.0821\n",
            "Epoch 628/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 163ms/step - loss: 0.0786 - val_loss: 0.0769\n",
            "Epoch 629/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0788 - val_loss: 0.0896\n",
            "Epoch 630/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.0798 - val_loss: 0.0801\n",
            "Epoch 631/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0737 - val_loss: 0.0701\n",
            "Epoch 632/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - loss: 0.0716 - val_loss: 0.0795\n",
            "Epoch 633/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - loss: 0.0823 - val_loss: 0.0836\n",
            "Epoch 634/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0793 - val_loss: 0.0791\n",
            "Epoch 635/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 136ms/step - loss: 0.0739 - val_loss: 0.0716\n",
            "Epoch 636/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 161ms/step - loss: 0.0713 - val_loss: 0.0877\n",
            "Epoch 637/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0798 - val_loss: 0.0743\n",
            "Epoch 638/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.0804 - val_loss: 0.0714\n",
            "Epoch 639/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 144ms/step - loss: 0.0714 - val_loss: 0.0771\n",
            "Epoch 640/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.0766 - val_loss: 0.0743\n",
            "Epoch 641/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - loss: 0.0748 - val_loss: 0.0831\n",
            "Epoch 642/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 146ms/step - loss: 0.0886 - val_loss: 0.0784\n",
            "Epoch 643/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 147ms/step - loss: 0.0741 - val_loss: 0.0716\n",
            "Epoch 644/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - loss: 0.0733 - val_loss: 0.0835\n",
            "Epoch 645/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - loss: 0.0753 - val_loss: 0.0733\n",
            "Epoch 646/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 166ms/step - loss: 0.0743 - val_loss: 0.0706\n",
            "Epoch 647/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - loss: 0.0711 - val_loss: 0.0857\n",
            "Epoch 648/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0884 - val_loss: 0.1074\n",
            "Epoch 649/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - loss: 0.0991 - val_loss: 0.1082\n",
            "Epoch 650/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - loss: 0.0993 - val_loss: 0.0734\n",
            "Epoch 651/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0719 - val_loss: 0.0780\n",
            "Epoch 652/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0768 - val_loss: 0.1108\n",
            "Epoch 653/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 157ms/step - loss: 0.0933 - val_loss: 0.0761\n",
            "Epoch 654/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0732 - val_loss: 0.0708\n",
            "Epoch 655/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0731 - val_loss: 0.0710\n",
            "Epoch 656/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 145ms/step - loss: 0.0716 - val_loss: 0.0697\n",
            "Epoch 657/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 135ms/step - loss: 0.0737 - val_loss: 0.0769\n",
            "Epoch 658/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - loss: 0.0739 - val_loss: 0.0693\n",
            "Epoch 659/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - loss: 0.0702 - val_loss: 0.0783\n",
            "Epoch 660/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - loss: 0.0730 - val_loss: 0.0794\n",
            "Epoch 661/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 123ms/step - loss: 0.0768 - val_loss: 0.0710\n",
            "Epoch 662/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 160ms/step - loss: 0.0715 - val_loss: 0.0693\n",
            "Epoch 663/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.0714 - val_loss: 0.0733\n",
            "Epoch 664/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0724 - val_loss: 0.0801\n",
            "Epoch 665/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - loss: 0.0765 - val_loss: 0.0851\n",
            "Epoch 666/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0868 - val_loss: 0.1004\n",
            "Epoch 667/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 125ms/step - loss: 0.0904 - val_loss: 0.0915\n",
            "Epoch 668/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 162ms/step - loss: 0.0780 - val_loss: 0.0688\n",
            "Epoch 669/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 121ms/step - loss: 0.0698 - val_loss: 0.0988\n",
            "Epoch 670/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 144ms/step - loss: 0.0846 - val_loss: 0.0753\n",
            "Epoch 671/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.0796 - val_loss: 0.0976\n",
            "Epoch 672/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - loss: 0.0835 - val_loss: 0.0754\n",
            "Epoch 673/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - loss: 0.0714 - val_loss: 0.0992\n",
            "Epoch 674/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0852 - val_loss: 0.0703\n",
            "Epoch 675/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - loss: 0.0716 - val_loss: 0.0698\n",
            "Epoch 676/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 144ms/step - loss: 0.0714 - val_loss: 0.0763\n",
            "Epoch 677/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0710 - val_loss: 0.0745\n",
            "Epoch 678/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - loss: 0.0735 - val_loss: 0.0741\n",
            "Epoch 679/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 140ms/step - loss: 0.0716 - val_loss: 0.0957\n",
            "Epoch 680/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0866 - val_loss: 0.0809\n",
            "Epoch 681/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - loss: 0.0750 - val_loss: 0.0877\n",
            "Epoch 682/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - loss: 0.0788 - val_loss: 0.0728\n",
            "Epoch 683/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - loss: 0.0701 - val_loss: 0.0687\n",
            "Epoch 684/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - loss: 0.0689 - val_loss: 0.1007\n",
            "Epoch 685/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0792 - val_loss: 0.0868\n",
            "Epoch 686/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0810 - val_loss: 0.1088\n",
            "Epoch 687/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - loss: 0.0831 - val_loss: 0.0701\n",
            "Epoch 688/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - loss: 0.0730 - val_loss: 0.0734\n",
            "Epoch 689/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 158ms/step - loss: 0.0708 - val_loss: 0.0723\n",
            "Epoch 690/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0715 - val_loss: 0.0743\n",
            "Epoch 691/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0726 - val_loss: 0.0747\n",
            "Epoch 692/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 159ms/step - loss: 0.0702 - val_loss: 0.1020\n",
            "Epoch 693/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - loss: 0.0811 - val_loss: 0.0785\n",
            "Epoch 694/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 158ms/step - loss: 0.0753 - val_loss: 0.0815\n",
            "Epoch 695/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 121ms/step - loss: 0.0816 - val_loss: 0.0796\n",
            "Epoch 696/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0782 - val_loss: 0.0782\n",
            "Epoch 697/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - loss: 0.0751 - val_loss: 0.0694\n",
            "Epoch 698/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 144ms/step - loss: 0.0705 - val_loss: 0.0780\n",
            "Epoch 699/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 158ms/step - loss: 0.0734 - val_loss: 0.0978\n",
            "Epoch 700/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 120ms/step - loss: 0.0872 - val_loss: 0.0811\n",
            "Epoch 701/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - loss: 0.0762 - val_loss: 0.0693\n",
            "Epoch 702/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 121ms/step - loss: 0.0693 - val_loss: 0.0845\n",
            "Epoch 703/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - loss: 0.0797 - val_loss: 0.0795\n",
            "Epoch 704/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 120ms/step - loss: 0.0903 - val_loss: 0.0719\n",
            "Epoch 705/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - loss: 0.0683 - val_loss: 0.0718\n",
            "Epoch 706/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0700 - val_loss: 0.0732\n",
            "Epoch 707/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - loss: 0.0737 - val_loss: 0.0775\n",
            "Epoch 708/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 155ms/step - loss: 0.0766 - val_loss: 0.0718\n",
            "Epoch 709/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 136ms/step - loss: 0.0690 - val_loss: 0.0686\n",
            "Epoch 710/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - loss: 0.0667 - val_loss: 0.0783\n",
            "Epoch 711/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0732 - val_loss: 0.0791\n",
            "Epoch 712/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 154ms/step - loss: 0.0756 - val_loss: 0.0778\n",
            "Epoch 713/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - loss: 0.0741 - val_loss: 0.0759\n",
            "Epoch 714/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 163ms/step - loss: 0.0749 - val_loss: 0.1061\n",
            "Epoch 715/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0868 - val_loss: 0.0717\n",
            "Epoch 716/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0740 - val_loss: 0.0712\n",
            "Epoch 717/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 166ms/step - loss: 0.0690 - val_loss: 0.0697\n",
            "Epoch 718/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0709 - val_loss: 0.0690\n",
            "Epoch 719/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - loss: 0.0726 - val_loss: 0.0725\n",
            "Epoch 720/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 150ms/step - loss: 0.0729 - val_loss: 0.0700\n",
            "Epoch 721/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 126ms/step - loss: 0.0699 - val_loss: 0.0943\n",
            "Epoch 722/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 152ms/step - loss: 0.0832 - val_loss: 0.0910\n",
            "Epoch 723/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 132ms/step - loss: 0.0797 - val_loss: 0.0725\n",
            "Epoch 724/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 140ms/step - loss: 0.0745 - val_loss: 0.0804\n",
            "Epoch 725/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0722 - val_loss: 0.0681\n",
            "Epoch 726/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - loss: 0.0675 - val_loss: 0.0678\n",
            "Epoch 727/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - loss: 0.0697 - val_loss: 0.0680\n",
            "Epoch 728/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 140ms/step - loss: 0.0690 - val_loss: 0.0676\n",
            "Epoch 729/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - loss: 0.0706 - val_loss: 0.0684\n",
            "Epoch 730/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0688 - val_loss: 0.0729\n",
            "Epoch 731/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - loss: 0.0702 - val_loss: 0.0774\n",
            "Epoch 732/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - loss: 0.0716 - val_loss: 0.0685\n",
            "Epoch 733/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0677 - val_loss: 0.0681\n",
            "Epoch 734/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - loss: 0.0707 - val_loss: 0.0940\n",
            "Epoch 735/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - loss: 0.0935 - val_loss: 0.0758\n",
            "Epoch 736/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 143ms/step - loss: 0.0742 - val_loss: 0.1168\n",
            "Epoch 737/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - loss: 0.0963 - val_loss: 0.1000\n",
            "Epoch 738/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0871 - val_loss: 0.0743\n",
            "Epoch 739/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - loss: 0.0756 - val_loss: 0.0825\n",
            "Epoch 740/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - loss: 0.0763 - val_loss: 0.0672\n",
            "Epoch 741/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.0703 - val_loss: 0.0694\n",
            "Epoch 742/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - loss: 0.0700 - val_loss: 0.0678\n",
            "Epoch 743/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 141ms/step - loss: 0.0664 - val_loss: 0.0674\n",
            "Epoch 744/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0688 - val_loss: 0.0875\n",
            "Epoch 745/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 131ms/step - loss: 0.0787 - val_loss: 0.0800\n",
            "Epoch 746/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - loss: 0.0707 - val_loss: 0.0778\n",
            "Epoch 747/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0775 - val_loss: 0.0693\n",
            "Epoch 748/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - loss: 0.0683 - val_loss: 0.0838\n",
            "Epoch 749/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 130ms/step - loss: 0.0772 - val_loss: 0.0758\n",
            "Epoch 750/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - loss: 0.0739 - val_loss: 0.0856\n",
            "Epoch 751/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - loss: 0.0762 - val_loss: 0.0801\n",
            "Epoch 752/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 128ms/step - loss: 0.0735 - val_loss: 0.0932\n",
            "Epoch 753/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - loss: 0.0781 - val_loss: 0.0831\n",
            "Epoch 754/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 154ms/step - loss: 0.0763 - val_loss: 0.0730\n",
            "Epoch 755/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - loss: 0.0724 - val_loss: 0.0707\n",
            "Epoch 756/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 156ms/step - loss: 0.0683 - val_loss: 0.0707\n",
            "Epoch 757/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0697 - val_loss: 0.0700\n",
            "Epoch 758/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - loss: 0.0690 - val_loss: 0.0750\n",
            "Epoch 759/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 156ms/step - loss: 0.0720 - val_loss: 0.0668\n",
            "Epoch 760/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - loss: 0.0681 - val_loss: 0.0771\n",
            "Epoch 761/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 142ms/step - loss: 0.0746 - val_loss: 0.0683\n",
            "Epoch 762/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 115ms/step - loss: 0.0723 - val_loss: 0.0676\n",
            "Epoch 763/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 137ms/step - loss: 0.0666 - val_loss: 0.0700\n",
            "Epoch 764/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 132ms/step - loss: 0.0675 - val_loss: 0.0697\n",
            "Epoch 765/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - loss: 0.0712 - val_loss: 0.0680\n",
            "Epoch 766/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - loss: 0.0691 - val_loss: 0.0796\n",
            "Epoch 767/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - loss: 0.0751 - val_loss: 0.0835\n",
            "Epoch 768/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 159ms/step - loss: 0.0795 - val_loss: 0.0857\n",
            "Epoch 769/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0846 - val_loss: 0.0686\n",
            "Epoch 770/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0663 - val_loss: 0.0768\n",
            "Epoch 771/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - loss: 0.0739 - val_loss: 0.0857\n",
            "Epoch 772/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.0745 - val_loss: 0.1107\n",
            "Epoch 773/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - loss: 0.0844 - val_loss: 0.1450\n",
            "Epoch 774/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 157ms/step - loss: 0.1198 - val_loss: 0.0804\n",
            "Epoch 775/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 125ms/step - loss: 0.0735 - val_loss: 0.0921\n",
            "Epoch 776/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 161ms/step - loss: 0.0780 - val_loss: 0.0726\n",
            "Epoch 777/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - loss: 0.0694 - val_loss: 0.0673\n",
            "Epoch 778/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - loss: 0.0676 - val_loss: 0.0725\n",
            "Epoch 779/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 145ms/step - loss: 0.0738 - val_loss: 0.0743\n",
            "Epoch 780/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.0680 - val_loss: 0.0666\n",
            "Epoch 781/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 145ms/step - loss: 0.0655 - val_loss: 0.0713\n",
            "Epoch 782/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 143ms/step - loss: 0.0689 - val_loss: 0.0705\n",
            "Epoch 783/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - loss: 0.0685 - val_loss: 0.0698\n",
            "Epoch 784/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 139ms/step - loss: 0.0673 - val_loss: 0.0678\n",
            "Epoch 785/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 142ms/step - loss: 0.0668 - val_loss: 0.1029\n",
            "Epoch 786/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0870 - val_loss: 0.0715\n",
            "Epoch 787/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 150ms/step - loss: 0.0678 - val_loss: 0.0735\n",
            "Epoch 788/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 122ms/step - loss: 0.0705 - val_loss: 0.1028\n",
            "Epoch 789/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 162ms/step - loss: 0.1048 - val_loss: 0.1127\n",
            "Epoch 790/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 122ms/step - loss: 0.0900 - val_loss: 0.0800\n",
            "Epoch 791/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 166ms/step - loss: 0.0832 - val_loss: 0.0819\n",
            "Epoch 792/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 131ms/step - loss: 0.0821 - val_loss: 0.0964\n",
            "Epoch 793/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 169ms/step - loss: 0.0824 - val_loss: 0.0708\n",
            "Epoch 794/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 128ms/step - loss: 0.0681 - val_loss: 0.0665\n",
            "Epoch 795/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 156ms/step - loss: 0.0700 - val_loss: 0.0681\n",
            "Epoch 796/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 135ms/step - loss: 0.0669 - val_loss: 0.0688\n",
            "Epoch 797/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - loss: 0.0681 - val_loss: 0.0688\n",
            "Epoch 798/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - loss: 0.0648 - val_loss: 0.0721\n",
            "Epoch 799/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - loss: 0.0685 - val_loss: 0.0665\n",
            "Epoch 800/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - loss: 0.0680 - val_loss: 0.0675\n",
            "Epoch 801/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 127ms/step - loss: 0.0657 - val_loss: 0.0696\n",
            "Epoch 802/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 162ms/step - loss: 0.0654 - val_loss: 0.0700\n",
            "Epoch 803/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 127ms/step - loss: 0.0691 - val_loss: 0.0741\n",
            "Epoch 804/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0674 - val_loss: 0.0714\n",
            "Epoch 805/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - loss: 0.0679 - val_loss: 0.1089\n",
            "Epoch 806/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - loss: 0.0916 - val_loss: 0.0655\n",
            "Epoch 807/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - loss: 0.0665 - val_loss: 0.0688\n",
            "Epoch 808/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0675 - val_loss: 0.0653\n",
            "Epoch 809/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - loss: 0.0658 - val_loss: 0.0960\n",
            "Epoch 810/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - loss: 0.0817 - val_loss: 0.0758\n",
            "Epoch 811/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0697 - val_loss: 0.0843\n",
            "Epoch 812/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 151ms/step - loss: 0.0774 - val_loss: 0.0787\n",
            "Epoch 813/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 120ms/step - loss: 0.0827 - val_loss: 0.0664\n",
            "Epoch 814/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 168ms/step - loss: 0.0664 - val_loss: 0.0791\n",
            "Epoch 815/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - loss: 0.0786 - val_loss: 0.0737\n",
            "Epoch 816/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - loss: 0.0685 - val_loss: 0.0705\n",
            "Epoch 817/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 156ms/step - loss: 0.0663 - val_loss: 0.0691\n",
            "Epoch 818/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 135ms/step - loss: 0.0693 - val_loss: 0.0659\n",
            "Epoch 819/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - loss: 0.0679 - val_loss: 0.0695\n",
            "Epoch 820/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0673 - val_loss: 0.0648\n",
            "Epoch 821/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - loss: 0.0661 - val_loss: 0.0690\n",
            "Epoch 822/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - loss: 0.0697 - val_loss: 0.0725\n",
            "Epoch 823/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0675 - val_loss: 0.0649\n",
            "Epoch 824/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 142ms/step - loss: 0.0639 - val_loss: 0.0769\n",
            "Epoch 825/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 141ms/step - loss: 0.0732 - val_loss: 0.0688\n",
            "Epoch 826/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0688 - val_loss: 0.0810\n",
            "Epoch 827/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - loss: 0.0713 - val_loss: 0.0688\n",
            "Epoch 828/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - loss: 0.0654 - val_loss: 0.0715\n",
            "Epoch 829/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0685 - val_loss: 0.0667\n",
            "Epoch 830/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 151ms/step - loss: 0.0665 - val_loss: 0.0977\n",
            "Epoch 831/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - loss: 0.0864 - val_loss: 0.0673\n",
            "Epoch 832/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - loss: 0.0669 - val_loss: 0.0652\n",
            "Epoch 833/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - loss: 0.0650 - val_loss: 0.0824\n",
            "Epoch 834/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - loss: 0.0691 - val_loss: 0.0654\n",
            "Epoch 835/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 127ms/step - loss: 0.0636 - val_loss: 0.1160\n",
            "Epoch 836/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 161ms/step - loss: 0.0947 - val_loss: 0.0686\n",
            "Epoch 837/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - loss: 0.0661 - val_loss: 0.0891\n",
            "Epoch 838/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0785 - val_loss: 0.0812\n",
            "Epoch 839/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 162ms/step - loss: 0.0688 - val_loss: 0.0977\n",
            "Epoch 840/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0835 - val_loss: 0.0687\n",
            "Epoch 841/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - loss: 0.0670 - val_loss: 0.0680\n",
            "Epoch 842/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 168ms/step - loss: 0.0661 - val_loss: 0.0657\n",
            "Epoch 843/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 133ms/step - loss: 0.0660 - val_loss: 0.0671\n",
            "Epoch 844/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 168ms/step - loss: 0.0705 - val_loss: 0.0662\n",
            "Epoch 845/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 131ms/step - loss: 0.0659 - val_loss: 0.0719\n",
            "Epoch 846/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 166ms/step - loss: 0.0663 - val_loss: 0.0829\n",
            "Epoch 847/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 125ms/step - loss: 0.0726 - val_loss: 0.0657\n",
            "Epoch 848/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 154ms/step - loss: 0.0647 - val_loss: 0.0780\n",
            "Epoch 849/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 135ms/step - loss: 0.0703 - val_loss: 0.0694\n",
            "Epoch 850/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 153ms/step - loss: 0.0668 - val_loss: 0.0656\n",
            "Epoch 851/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 131ms/step - loss: 0.0709 - val_loss: 0.0772\n",
            "Epoch 852/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - loss: 0.0759 - val_loss: 0.0762\n",
            "Epoch 853/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0756 - val_loss: 0.0681\n",
            "Epoch 854/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 125ms/step - loss: 0.0640 - val_loss: 0.0678\n",
            "Epoch 855/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - loss: 0.0692 - val_loss: 0.0642\n",
            "Epoch 856/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0642 - val_loss: 0.0813\n",
            "Epoch 857/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0706 - val_loss: 0.0642\n",
            "Epoch 858/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 139ms/step - loss: 0.0627 - val_loss: 0.0642\n",
            "Epoch 859/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0639 - val_loss: 0.0810\n",
            "Epoch 860/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 146ms/step - loss: 0.0702 - val_loss: 0.0685\n",
            "Epoch 861/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 122ms/step - loss: 0.0664 - val_loss: 0.0657\n",
            "Epoch 862/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 153ms/step - loss: 0.0644 - val_loss: 0.0753\n",
            "Epoch 863/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 123ms/step - loss: 0.0791 - val_loss: 0.0679\n",
            "Epoch 864/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 154ms/step - loss: 0.0719 - val_loss: 0.0892\n",
            "Epoch 865/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 127ms/step - loss: 0.0804 - val_loss: 0.0775\n",
            "Epoch 866/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - loss: 0.0697 - val_loss: 0.0742\n",
            "Epoch 867/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0673 - val_loss: 0.0915\n",
            "Epoch 868/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - loss: 0.0805 - val_loss: 0.0722\n",
            "Epoch 869/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - loss: 0.0681 - val_loss: 0.0856\n",
            "Epoch 870/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0795 - val_loss: 0.0913\n",
            "Epoch 871/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 157ms/step - loss: 0.0708 - val_loss: 0.0661\n",
            "Epoch 872/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - loss: 0.0673 - val_loss: 0.0655\n",
            "Epoch 873/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 119ms/step - loss: 0.0638 - val_loss: 0.0707\n",
            "Epoch 874/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - loss: 0.0661 - val_loss: 0.0645\n",
            "Epoch 875/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - loss: 0.0643 - val_loss: 0.0847\n",
            "Epoch 876/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 161ms/step - loss: 0.0745 - val_loss: 0.0657\n",
            "Epoch 877/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - loss: 0.0657 - val_loss: 0.0700\n",
            "Epoch 878/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - loss: 0.0677 - val_loss: 0.0796\n",
            "Epoch 879/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 156ms/step - loss: 0.0732 - val_loss: 0.0715\n",
            "Epoch 880/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 128ms/step - loss: 0.0709 - val_loss: 0.0687\n",
            "Epoch 881/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - loss: 0.0672 - val_loss: 0.0861\n",
            "Epoch 882/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0740 - val_loss: 0.0652\n",
            "Epoch 883/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 128ms/step - loss: 0.0636 - val_loss: 0.0714\n",
            "Epoch 884/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 145ms/step - loss: 0.0654 - val_loss: 0.1154\n",
            "Epoch 885/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - loss: 0.1036 - val_loss: 0.1023\n",
            "Epoch 886/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 130ms/step - loss: 0.0773 - val_loss: 0.0945\n",
            "Epoch 887/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 136ms/step - loss: 0.0742 - val_loss: 0.0650\n",
            "Epoch 888/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0637 - val_loss: 0.0632\n",
            "Epoch 889/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 141ms/step - loss: 0.0649 - val_loss: 0.0856\n",
            "Epoch 890/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - loss: 0.0714 - val_loss: 0.0646\n",
            "Epoch 891/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0647 - val_loss: 0.0773\n",
            "Epoch 892/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - loss: 0.0706 - val_loss: 0.0681\n",
            "Epoch 893/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 140ms/step - loss: 0.0663 - val_loss: 0.0748\n",
            "Epoch 894/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.0708 - val_loss: 0.0918\n",
            "Epoch 895/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - loss: 0.0772 - val_loss: 0.0689\n",
            "Epoch 896/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 131ms/step - loss: 0.0672 - val_loss: 0.0777\n",
            "Epoch 897/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - loss: 0.0696 - val_loss: 0.0654\n",
            "Epoch 898/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 156ms/step - loss: 0.0686 - val_loss: 0.0780\n",
            "Epoch 899/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - loss: 0.0667 - val_loss: 0.0639\n",
            "Epoch 900/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 161ms/step - loss: 0.0655 - val_loss: 0.0638\n",
            "Epoch 901/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0629 - val_loss: 0.0637\n",
            "Epoch 902/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 121ms/step - loss: 0.0633 - val_loss: 0.0915\n",
            "Epoch 903/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 165ms/step - loss: 0.0968 - val_loss: 0.0664\n",
            "Epoch 904/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 120ms/step - loss: 0.0667 - val_loss: 0.1277\n",
            "Epoch 905/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 156ms/step - loss: 0.0910 - val_loss: 0.0645\n",
            "Epoch 906/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 150ms/step - loss: 0.0635 - val_loss: 0.0683\n",
            "Epoch 907/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 127ms/step - loss: 0.0642 - val_loss: 0.0643\n",
            "Epoch 908/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - loss: 0.0661 - val_loss: 0.0646\n",
            "Epoch 909/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 122ms/step - loss: 0.0640 - val_loss: 0.0632\n",
            "Epoch 910/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 160ms/step - loss: 0.0628 - val_loss: 0.0626\n",
            "Epoch 911/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 123ms/step - loss: 0.0619 - val_loss: 0.0793\n",
            "Epoch 912/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 164ms/step - loss: 0.0669 - val_loss: 0.0668\n",
            "Epoch 913/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0673 - val_loss: 0.0687\n",
            "Epoch 914/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0679 - val_loss: 0.0866\n",
            "Epoch 915/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 160ms/step - loss: 0.0831 - val_loss: 0.0822\n",
            "Epoch 916/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - loss: 0.0758 - val_loss: 0.0714\n",
            "Epoch 917/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 135ms/step - loss: 0.0733 - val_loss: 0.0681\n",
            "Epoch 918/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 149ms/step - loss: 0.0673 - val_loss: 0.0954\n",
            "Epoch 919/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 118ms/step - loss: 0.0838 - val_loss: 0.0641\n",
            "Epoch 920/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 129ms/step - loss: 0.0628 - val_loss: 0.0709\n",
            "Epoch 921/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 148ms/step - loss: 0.0676 - val_loss: 0.0798\n",
            "Epoch 922/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 137ms/step - loss: 0.0719 - val_loss: 0.0789\n",
            "Epoch 923/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 144ms/step - loss: 0.0710 - val_loss: 0.0856\n",
            "Epoch 924/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 0.0704 - val_loss: 0.0833\n",
            "Epoch 925/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 123ms/step - loss: 0.0773 - val_loss: 0.0838\n",
            "Epoch 926/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - loss: 0.0730 - val_loss: 0.0690\n",
            "Epoch 927/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 138ms/step - loss: 0.0665 - val_loss: 0.0854\n",
            "Epoch 928/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 149ms/step - loss: 0.0692 - val_loss: 0.0698\n",
            "Epoch 929/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 136ms/step - loss: 0.0660 - val_loss: 0.0844\n",
            "Epoch 930/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - loss: 0.0693 - val_loss: 0.0892\n",
            "Epoch 931/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 117ms/step - loss: 0.0748 - val_loss: 0.0634\n",
            "Epoch 932/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step - loss: 0.0628 - val_loss: 0.0636\n",
            "Epoch 933/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 146ms/step - loss: 0.0622 - val_loss: 0.0753\n",
            "Epoch 934/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 140ms/step - loss: 0.0761 - val_loss: 0.1173\n",
            "Epoch 935/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - loss: 0.0918 - val_loss: 0.0784\n",
            "Epoch 936/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - loss: 0.0750 - val_loss: 0.0674\n",
            "Epoch 937/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 148ms/step - loss: 0.0647 - val_loss: 0.0839\n",
            "Epoch 938/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 137ms/step - loss: 0.0690 - val_loss: 0.0806\n",
            "Epoch 939/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 123ms/step - loss: 0.0750 - val_loss: 0.0792\n",
            "Epoch 940/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 165ms/step - loss: 0.0698 - val_loss: 0.0785\n",
            "Epoch 941/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 124ms/step - loss: 0.0702 - val_loss: 0.0640\n",
            "Epoch 942/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.0638 - val_loss: 0.0821\n",
            "Epoch 943/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 155ms/step - loss: 0.0736 - val_loss: 0.0769\n",
            "Epoch 944/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 121ms/step - loss: 0.0716 - val_loss: 0.0646\n",
            "Epoch 945/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - loss: 0.0634 - val_loss: 0.0654\n",
            "Epoch 946/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 160ms/step - loss: 0.0673 - val_loss: 0.0640\n",
            "Epoch 947/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 119ms/step - loss: 0.0676 - val_loss: 0.0844\n",
            "Epoch 948/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 164ms/step - loss: 0.0736 - val_loss: 0.0676\n",
            "Epoch 949/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0670 - val_loss: 0.0667\n",
            "Epoch 950/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 120ms/step - loss: 0.0619 - val_loss: 0.0896\n",
            "Epoch 951/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 158ms/step - loss: 0.0714 - val_loss: 0.0753\n",
            "Epoch 952/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 121ms/step - loss: 0.0701 - val_loss: 0.0671\n",
            "Epoch 953/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 150ms/step - loss: 0.0658 - val_loss: 0.0638\n",
            "Epoch 954/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 129ms/step - loss: 0.0686 - val_loss: 0.0700\n",
            "Epoch 955/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 133ms/step - loss: 0.0680 - val_loss: 0.0646\n",
            "Epoch 956/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - loss: 0.0627 - val_loss: 0.0747\n",
            "Epoch 957/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 159ms/step - loss: 0.0680 - val_loss: 0.0678\n",
            "Epoch 958/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 116ms/step - loss: 0.0653 - val_loss: 0.0688\n",
            "Epoch 959/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 122ms/step - loss: 0.0670 - val_loss: 0.0723\n",
            "Epoch 960/1000\n",
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 166ms/step - loss: 0.0848 - val_loss: 0.0905\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06263846158981323"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_selected= test_set[['hour',\n",
        " 'day_of_week',\n",
        " 'month',\n",
        " 'load_lag_198',\n",
        " 'load_lag_336',\n",
        " 'Rolling_Std_15',\n",
        " 'Rolling_Sum_30',\n",
        " 'temp_lag_1',\n",
        " 'temp_lag_3',\n",
        " 'temp_mean_6',\n",
        " 'temp_mean_24',\n",
        " 'temp_lag_24',\n",
        " 'temp_max',\n",
        " 'HDD']]\n",
        "\n",
        "target = test_set['Load_DA'].values\n",
        "\n",
        "    # Normalize the selected features\n",
        "scaler = RobustScaler()\n",
        "X_selected_scaled = scaler.fit_transform(X_selected)\n",
        "target_scaled = scaler.fit_transform(target.reshape(-1, 1))\n",
        "\n",
        "    # Reshape the target variable to have the shape (number of samples, 192)\n",
        "y_t = np.array([target_scaled[i:i+192] for i in range(0, len(target_scaled) - 192 + 1, 24)])\n",
        "\n",
        "    # Adjust the input features accordingly\n",
        "X_t = np.array([X_selected_scaled[i:i+192, :] for i in range(0, len(X_selected_scaled) - 192 + 1, 24)])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NIUOV_Ou7Zvy"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_t[:1])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWgurdXkJ4G1",
        "outputId": "619ed883-acce-4c69-c100-55f9f76901e4"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_rescaled = scaler.inverse_transform(y_pred.reshape(-1, 1)).reshape(y_pred.shape)\n",
        "y_test_rescaled = scaler.inverse_transform(y_test.reshape(-1, 1)).reshape(y_test.shape)\n"
      ],
      "metadata": {
        "id": "xwVapiaCbNmn"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction for the first sample in X_test\n",
        "y_pred_single = model.predict(X_test[:1])  # This will output shape (1, 192)\n",
        "\n",
        "# Rescale the prediction back to the original scale\n",
        "y_pred_single_rescaled = scaler.inverse_transform(y_pred_single.flatten().reshape(-1, 1)).reshape(y_pred_single.shape)\n",
        "\n",
        "# Rescale the true value (y_test[:1]) back to the original scale\n",
        "y_true_single_rescaled = scaler.inverse_transform(y_test[:1].flatten().reshape(-1, 1)).reshape(y_test[:1].shape)\n",
        "\n",
        "# Check shapes\n",
        "print(f\"y_pred_single_rescaled shape: {y_pred_single_rescaled.shape}\")\n",
        "print(f\"y_true_single_rescaled shape: {y_true_single_rescaled.shape}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FqPbXZEbPm7",
        "outputId": "d82cfae7-fbd8-4f6f-d97e-241e7f4623c4"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step\n",
            "y_pred_single_rescaled shape: (1, 192, 192)\n",
            "y_true_single_rescaled shape: (1, 192, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction for the first sample in X_test\n",
        "y_pred_single = model.predict(X_test[:1])  # This will output shape (1, 192, 192)\n",
        "\n",
        "# Rescale the prediction back to the original scale\n",
        "# Reshape to (1, 192, 1) by selecting the first feature if needed\n",
        "y_pred_single_rescaled = scaler.inverse_transform(y_pred_single.reshape(-1, 192)[:, 0].reshape(-1, 1)).reshape(1, 192, 1)\n",
        "\n",
        "# Rescale the true value (y_test[:1]) back to the original scale\n",
        "y_true_single_rescaled = scaler.inverse_transform(y_test[:1].reshape(-1, 1)).reshape(y_test[:1].shape)\n",
        "\n",
        "# Check shapes after fixing\n",
        "print(f\"y_pred_single_rescaled shape: {y_pred_single_rescaled.shape}\")\n",
        "print(f\"y_true_single_rescaled shape: {y_true_single_rescaled.shape}\")\n",
        "\n",
        "# Calculate the MAE for the single prediction\n",
        "mae_single = mean_absolute_error(y_true_single_rescaled.flatten(), y_pred_single_rescaled.flatten())\n",
        "\n",
        "print(f\"Mean Absolute Error for the first sample: {mae_single}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3uUbs3QbmXv",
        "outputId": "4acbfa9b-8acf-4acb-da90-7c0bfb881f74"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "y_pred_single_rescaled shape: (1, 192, 1)\n",
            "y_true_single_rescaled shape: (1, 192, 1)\n",
            "Mean Absolute Error for the first sample: 505.191873811749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the arrays before plotting\n",
        "y_pred_single_flat = y_pred_single_rescaled.flatten()  # Shape (192,)\n",
        "y_true_single_flat = y_true_single_rescaled.flatten()  # Shape (192,)\n",
        "\n",
        "# Plot the actual vs predicted values\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_true_single_flat, label='Actual Values')  # Plot true values\n",
        "plt.plot(y_pred_single_flat, label='Predicted Values')  # Plot predicted values\n",
        "\n",
        "plt.legend()\n",
        "plt.title('Actual vs Predicted Load for a Single Sample')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "jnKvI-VWb0Ya",
        "outputId": "1a42f7d7-2d67-4e8f-d4f7-71f5b18c78fc"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QilrtJnha56b"
      }
    }
  ]
}